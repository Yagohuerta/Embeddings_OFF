{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f30e6a11",
   "metadata": {},
   "source": [
    "# **Importamos las dependencias**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d938dfe",
   "metadata": {},
   "source": [
    "Estoy importando todas las dependencias de mis cuadernos, despues las depuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "738a5349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Importaciones para Manejo de Archivos y Directorios ---\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "# --- Importamos Vertex AI ---\n",
    "import vertexai\n",
    "\n",
    "\n",
    "# --- Importaciones para Visualización y Formato de Texto ---\n",
    "\n",
    "# Se utiliza para mostrar contenido enriquecido, como texto con formato Markdown,\n",
    "# directamente en entornos como Jupyter Notebooks o IPython.\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Importa la clase `Markdown` de la biblioteca `rich`, que sirve para renderizar\n",
    "# Markdown con formato avanzado en la terminal. Se le da un alias `RichMarkdown`\n",
    "# para evitar conflictos de nombre con la importación anterior.\n",
    "from rich.markdown import Markdown as RichMarkdown\n",
    "\n",
    "\n",
    "# --- Importaciones para el Modelo Generativo de Vertex AI ---\n",
    "\n",
    "# Importa las clases necesarias del SDK de Vertex AI para interactuar con los modelos generativos.\n",
    "# - GenerationConfig: Para configurar los parámetros de la respuesta (ej. temperatura, top_p).\n",
    "# - GenerativeModel: La clase principal para cargar y usar un modelo generativo como Gemini.\n",
    "# - Image: Para manejar y enviar imágenes como parte de la entrada al modelo (enfoque multimodal).\n",
    "from vertexai.generative_models import GenerationConfig, GenerativeModel, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81a731d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Para el proceso de datos y visualización ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "\n",
    "# --- Para manejar las variables de entorno ---\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# --- Desactiva las advertencias de asignaciones encadenadas en pandas para evitar mensajes de warning al modificar DataFrames.\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "\n",
    "# --- Dependencias de Vertex AI ---\n",
    "import vertexai                                              # Importa el módulo principal de Vertex AI.\n",
    "from vertexai import init                                    # Inicializa Vertex AI con las credenciales y configuraciones necesarias.\n",
    "from vertexai.vision_models import Image as VMImage          # Importa la clase Image de Vertex AI para manejar imágenes.\n",
    "from vertexai.vision_models import MultiModalEmbeddingModel  # Importa el modelo de embeddings multimodales de Vertex AI para procesar imágenes y videos.\n",
    "from vertexai.vision_models import Video                     # Clase para manejar archivos de video en Vertex AI.\n",
    "from vertexai.vision_models import VideoSegmentConfig        # Configuración para segmentar videos\n",
    "from vertexai.generative_models import GenerativeModel       # Importa la clase para modelos generativos, como Gemini.\n",
    "from vertexai.generative_models import Part                  # Importa la clase Part para manejar partes de un mensaje, como texto o imágenes.\n",
    "\n",
    "\n",
    "# --- Para conectarse y consultar un endpoint de búsqueda vectorial (Vector Search) en Vertex AI. \n",
    "from google.cloud.aiplatform.matching_engine import MatchingEngineIndexEndpoint \n",
    "\n",
    "# --- Para acceder a los buckets de Google Cloud Storage y manejar archivos.\n",
    "from google.cloud import storage\n",
    "\n",
    "\n",
    "# --- Dependencias para poder visualizar ---\n",
    "from IPython.display import Video as MVideo                  # Permite mostrar videos directamente en celdas de Jupyter Notebook.\n",
    "from IPython.display import HTML                             # Permite mostrar contenido HTML en celdas de Jupyter Notebook.\n",
    "from IPython.display import Image as ImageByte               # Permite mostrar imágenes en el notebook (renombrado como ImageByte para evitar conflictos de nombres).\n",
    "from IPython.display import display                          # Función general para mostrar objetos en el notebook.\n",
    "from sklearn.metrics.pairwise import cosine_similarity       # Función para calcular la similitud coseno entre vectores, útil para comparar embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628156ac",
   "metadata": {},
   "source": [
    "# **Configuración de credenciales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "403e2df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proyecto: constant-setup-463820-p6, Ubicación: us-central1, Índice: 1206368764833038336, Endpoint: mexicocostarica_1750850443317, Bucket: vboxiooof, Ruta de Videos: Videos/Videos_Segmentados\n"
     ]
    }
   ],
   "source": [
    "# --- Carga las Variables de Entorno ---\n",
    "load_dotenv()\n",
    "\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\")                        # ID del proyecto de Google Cloud\n",
    "LOCATION = os.getenv(\"LOCATION\")                            # Región donde se encuentran los recursos de Vertex AI\n",
    "INDEX_ID = os.getenv(\"INDEX_ID\")                            # ID del índice de búsqueda vectorial en Vertex AI\n",
    "ENDPOINT_ID = os.getenv(\"ENDPOINT_ID\")                      # ID del endpoint de búsqueda vectorial en Vertex AI\n",
    "BUCKET_NAME = os.getenv(\"BUCKET_NAME\")                      # Nombre del bucket de Google Cloud Storage donde se almacenan los videos\n",
    "VIDEO_FOLDER_PATH = os.getenv(\"VIDEO_FOLDER_PATH\")          # Ruta del folder dentro del bucket donde se encuentran los videos\n",
    "\n",
    "# Verificamos que las variebles de entorno esten bien\n",
    "print(f\"Proyecto: {PROJECT_ID}, Ubicación: {LOCATION}, Índice: {INDEX_ID}, Endpoint: {ENDPOINT_ID}, Bucket: {BUCKET_NAME}, Ruta de Videos: {VIDEO_FOLDER_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb909a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciamos Vertex AI con el proyecto y la ubicación especificados.\n",
    "init(project = PROJECT_ID, location = LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f569329e",
   "metadata": {},
   "source": [
    "# **Configuración de Vertex AI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d06bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inicialización del LLM ---\n",
    "model = GenerativeModel('gemini-2.5-flash-lite-preview-06-17')\n",
    "embedding_model = MultiModalEmbeddingModel.from_pretrained(\"multimodalembedding@001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15024b8f",
   "metadata": {},
   "source": [
    "# **Funciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b1f799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_videos_similares(texto_de_la_pregunta, cantidad_de_resultados=5):\n",
    "\n",
    "    \"\"\"\n",
    "    Hacemos el embedding de la pregunta, y buscamos en Vector Search los videos más similares.\n",
    "    Devolvemos las URIs de los videos encontrados.\n",
    "\n",
    "    Args:\n",
    "        texto_de_la_pregunta (str): La pregunta o consulta para buscar videos similares.\n",
    "        cantidad_de_resultados (int): Número de resultados a devolver. Por defecto es 5.\n",
    "\n",
    "    Returns:\n",
    "        list: Una lista de URIs de los videos encontrados que son similares a la pregunta.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    print(f'--- 1.- Hacemos el embedding de la pregunta: {texto_de_la_pregunta} ---')\n",
    "\n",
    "    # Hacemos el embedding de la pregunta\n",
    "    try:\n",
    "        vector_de_la_pregunta = embedding_model.get_embeddings(\n",
    "            contextual_text = texto_de_la_pregunta\n",
    "        ).text_embedding\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Error al hacer el embedding de la pregunta: {e}')\n",
    "        return []\n",
    "    \n",
    "    print('Fin del paso 1.\\n')\n",
    "\n",
    "\n",
    "    print(f'\\n --- 2.- Nos conectamos a Vector Search ---')\n",
    "\n",
    "    my_index_endpoint = MatchingEngineIndexEndpoint(\n",
    "        INDEX_ID = ENDPOINT_ID\n",
    "    )\n",
    "\n",
    "    print('Fin del paso 2.\\n')\n",
    "\n",
    "\n",
    "\n",
    "    print(f'\\n --- 3.- Buscamos los {cantidad_de_resultados} videos más similares a la pregunta ---')\n",
    "\n",
    "    try:\n",
    "        # Buscamos usando la técnica de 'nearest neighbors'\n",
    "        response = my_index_endpoint.find_neighbors(\n",
    "\n",
    "            queries = [vector_de_la_pregunta],      # Usamos el embedding de la pregunta\n",
    "            ENDPOINT_ID = INDEX_ID,           # ID del índice desplegado\n",
    "            num_neighbors = cantidad_de_resultados  # Número de vecinos a buscar\n",
    "\n",
    "        )\n",
    "\n",
    "        # Extraemos las URIs de los videos encontrados\n",
    "        uris_completas = []\n",
    "\n",
    "        if response and response[0]:\n",
    "            for neighbor in response[0]:\n",
    "                segment_id_base = neighbor.id # Nos da por ejemplo: \"mexicosta_segment_1\"\n",
    "\n",
    "                # Extraemos el prefijo y el número del ID\n",
    "                match = re.match(r\"(.*_)(\\d+)\", segment_id_base)\n",
    "                if match:\n",
    "                    prefijo = match.group(1) # \"mexicosta_segment_\"\n",
    "                    numero = match.group(2)  # \"1\" \n",
    "                    \n",
    "                    # Formateamos el número a 3 dígitos con ceros a la izquierda (ej. \"001\")\n",
    "                    numero_formateado = numero.zfill(3)\n",
    "                    \n",
    "                    # Reconstruimos el nombre del archivo final\n",
    "                    nombre_archivo_final = f\"{prefijo}{numero_formateado}\"\n",
    "                    \n",
    "                    # Creamos la URI completa con la extensión .mkv\n",
    "                    uri = f\"gs://{BUCKET_NAME}/{VIDEO_FOLDER_PATH}/{nombre_archivo_final}.mkv\"\n",
    "                    uris_completas.append(uri)\n",
    "                \n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'Error al buscar los videos similares: {e}')\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7156d451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_fragmentos_con_gemini(\n",
    "    pregunta_original: str,\n",
    "    uris_de_videos: list[str]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Toma la pregunta y una lista de URIs de video, las envía a Gemini\n",
    "    y devuelve la respuesta generada por el modelo.\n",
    "    \"\"\"\n",
    "    if not uris_de_videos:\n",
    "        return \"No se encontraron videos relevantes para analizar.\"\n",
    "\n",
    "    print(f\"\\nPASO 3.1: Preparando {len(uris_de_videos)} videos para enviar a Gemini...\")\n",
    "    \n",
    "    # Convertimos cada URI de video en un objeto 'Part' que Gemini entiende\n",
    "    video_parts = [Part.from_uri(uri, mime_type=\"video/mkv\") for uri in uris_de_videos]\n",
    "\n",
    "    # Construimos el prompt para el modelo\n",
    "    prompt_completo = [\n",
    "        \"Eres un asistente experto en análisis de video.\",\n",
    "        \"Tu tarea es analizar los siguientes fragmentos de video que te proporciono y responder a la pregunta del usuario de la forma más detallada posible basándote ÚNICAMENTE en el contenido de estos videos.\",\n",
    "        \"\\n---\",\n",
    "        \"PREGUNTA DEL USUARIO:\",\n",
    "        pregunta_original,\n",
    "        \"\\n---\",\n",
    "        \"FRAGMENTOS DE VIDEO A ANALIZAR:\",\n",
    "        *video_parts\n",
    "    ]\n",
    "\n",
    "    print(\"PASO 3.2: Enviando la solicitud a Gemini... (Esto puede tardar un poco)\")\n",
    "    try:\n",
    "        # Enviamos el prompt completo al modelo generativo\n",
    "        response = model.generate_content(prompt_completo)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Ocurrió un error al contactar con el modelo Gemini: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1924493a",
   "metadata": {},
   "source": [
    "# **Pruebas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885392fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# --- SCRIPT FINAL (VERSIÓN 3 - CORREGIDO CON CÓDIGO DE LA CONSOLA) ---\n",
    "# --------------------------------------------------------------------------\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "import vertexai\n",
    "from google.cloud import aiplatform\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "from vertexai.vision_models import MultiModalEmbeddingModel\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# --- 1. CONFIGURACIÓN Y CLIENTES (¡CON LOS IDs EXACTOS!) ---\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "# --- Constantes para la Configuración de Vertex AI Search (DE TU CÓDIGO) ---\n",
    "# ¡CORRECCIÓN FINAL! Usamos el nombre de recurso completo del endpoint.\n",
    "INDEX_ENDPOINT_RESOURCE_NAME = \"projects/640283206292/locations/us-central1/indexEndpoints/1468492336894836736\"\n",
    "# ¡CORRECCIÓN FINAL! Usamos el ID del índice desplegado que te dio la consola.\n",
    "ENDPOINT_ID = \"mexicocostarica_1750850443317\"\n",
    "\n",
    "# --- Constantes de tu Bucket (se mantienen igual) ---\n",
    "BUCKET_NAME = \"vboxiooof\"\n",
    "VIDEO_FOLDER_PATH = \"Videos/Videos_Segmentados\"\n",
    "\n",
    "# --- Inicialización de Clientes de Vertex AI ---\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\")\n",
    "LOCATION = os.getenv(\"LOCATION\")\n",
    "\n",
    "if not PROJECT_ID or not LOCATION:\n",
    "    raise ValueError(\"Asegúrate de que GCP_PROJECT_ID y GCP_REGION están en tu archivo .env\")\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "embedding_model = MultiModalEmbeddingModel.from_pretrained(\"multimodalembedding@001\")\n",
    "generative_model = GenerativeModel(\"gemini-2.0-flash-lite-001\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# --- 2. FUNCIÓN DE BÚSQUEDA (El código interno no cambia) ---\n",
    "# --------------------------------------------------------------------------\n",
    "def buscar_videos_similares(\n",
    "    texto_de_la_pregunta: str,\n",
    "    cantidad_de_resultados: int = 5\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Toma una pregunta, la convierte en un embedding, busca en Vertex AI Search\n",
    "    los IDs de videos más similares, reconstruye sus URIs de GCS y las devuelve.\n",
    "    \"\"\"\n",
    "    print(f\"PASO 2.1: Creando embedding para la pregunta: '{texto_de_la_pregunta}'\")\n",
    "    try:\n",
    "        vector_de_la_pregunta = embedding_model.get_embeddings(\n",
    "            contextual_text=texto_de_la_pregunta\n",
    "        ).text_embedding\n",
    "    except Exception as e:\n",
    "        print(f\"Error al generar embedding de texto: {e}\")\n",
    "        return []\n",
    "\n",
    "    print(\"PASO 2.2: Conectando al endpoint de Vertex AI Search...\")\n",
    "    # Esta línea ahora usará el nombre de recurso completo.\n",
    "    my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(\n",
    "        INDEX_ID=INDEX_ENDPOINT_RESOURCE_NAME\n",
    "    )\n",
    "\n",
    "    print(f\"PASO 2.3: Buscando {cantidad_de_resultados} videos similares...\")\n",
    "    try:\n",
    "        # Esta línea ahora usará el ENDPOINT_ID correcto.\n",
    "        response = my_index_endpoint.find_neighbors(\n",
    "            queries=[vector_de_la_pregunta],\n",
    "            ENDPOINT_ID=ENDPOINT_ID,\n",
    "            num_neighbors=cantidad_de_resultados,\n",
    "        )\n",
    "\n",
    "        uris_completas = []\n",
    "        if response and response[0]:\n",
    "            for neighbor in response[0]:\n",
    "                segment_id_base = neighbor.id\n",
    "                match = re.match(r\"(.*_)(\\d+)\", segment_id_base)\n",
    "                if match:\n",
    "                    prefijo, numero = match.groups()\n",
    "                    numero_formateado = numero.zfill(3)\n",
    "                    nombre_archivo_final = f\"{prefijo}{numero_formateado}\"\n",
    "                    uri = f\"gs://{BUCKET_NAME}/{VIDEO_FOLDER_PATH}/{nombre_archivo_final}.mkv\"\n",
    "                    uris_completas.append(uri)\n",
    "\n",
    "        print(f\"PASO 2.4: ¡Éxito! URIs encontradas: {uris_completas}\")\n",
    "        return uris_completas\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurrió un error al consultar Vertex AI Search: {e}\")\n",
    "        return []\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# --- 3. FUNCIÓN DE ANÁLISIS CON GEMINI (Sin cambios) ---\n",
    "# --------------------------------------------------------------------------\n",
    "def analizar_fragmentos_con_gemini(\n",
    "    pregunta_original: str,\n",
    "    uris_de_videos: list[str]\n",
    ") -> str:\n",
    "    if not uris_de_videos:\n",
    "        return \"No se encontraron videos relevantes para analizar.\"\n",
    "\n",
    "    print(f\"\\nPASO 3.1: Preparando {len(uris_de_videos)} videos para enviar a Gemini...\")\n",
    "    video_parts = [Part.from_uri(uri, mime_type=\"video/mkv\") for uri in uris_de_videos]\n",
    "    prompt_completo = [\n",
    "        \"Eres un asistente experto en análisis de video.\",\n",
    "        \"Tu tarea es analizar los siguientes fragmentos de video que te proporciono y responder a la pregunta del usuario de la forma más detallada posible basándote ÚNICAMENTE en el contenido de estos videos.\",\n",
    "        \"\\n---\",\n",
    "        \"PREGUNTA DEL USUARIO:\",\n",
    "        pregunta_original,\n",
    "        \"\\n---\",\n",
    "        \"FRAGMENTOS DE VIDEO A ANALIZAR:\",\n",
    "        *video_parts\n",
    "    ]\n",
    "    print(\"PASO 3.2: Enviando la solicitud a Gemini... (Esto puede tardar un poco)\")\n",
    "    try:\n",
    "        response = generative_model.generate_content(prompt_completo)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Ocurrió un error al contactar con el modelo Gemini: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dcfe01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INICIANDO PROCESO DE RAG MULTIMODAL ---\n",
      "PASO 2.1: Creando embedding para la pregunta: 'Muestrame a la marca Caliente'\n",
      "PASO 2.2: Conectando al endpoint de Vertex AI Search...\n",
      "PASO 2.3: Buscando 5 videos similares...\n",
      "PASO 2.4: ¡Éxito! URIs encontradas: ['gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_1095.mkv', 'gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_167.mkv', 'gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_910.mkv', 'gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_909.mkv', 'gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_1055.mkv']\n",
      "\n",
      "PASO 3.1: Preparando 5 videos para enviar a Gemini...\n",
      "PASO 3.2: Enviando la solicitud a Gemini... (Esto puede tardar un poco)\n",
      "\n",
      "--- RESPUESTA FINAL DE GEMINI ---\n",
      "Ocurrió un error al contactar con el modelo Gemini: 400 Request contains an invalid argument.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# --- 4. EJECUCIÓN DEL FLUJO COMPLETO (Sin cambios) ---\n",
    "# --------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    pregunta_del_usuario = \"Muestrame a la marca Caliente\"\n",
    "    print(\"--- INICIANDO PROCESO DE RAG MULTIMODAL ---\")\n",
    "    uris_relevantes = buscar_videos_similares(pregunta_del_usuario)\n",
    "    respuesta_final = analizar_fragmentos_con_gemini(pregunta_del_usuario, uris_relevantes)\n",
    "    print(\"\\n--- RESPUESTA FINAL DE GEMINI ---\")\n",
    "    print(respuesta_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
