{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ce26080",
   "metadata": {},
   "source": [
    "# **Importamos las dependencias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98ed9793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: google-cloud-aiplatform 1.71.1 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Instalación de todas las dependencias necesarias\n",
    "%pip install google-cloud-storage google-cloud-aiplatform vertexai matplotlib seaborn scikit-learn pandas seaborn numpy python-dotenv --quiet\n",
    "%pip install python-dotenv --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d508109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Para el proceso de datos y visualización ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# --- Para manejar las variables de entorno ---\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# --- Desactiva las advertencias de asignaciones encadenadas en pandas para evitar mensajes de warning al modificar DataFrames.\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "\n",
    "# --- Dependencias de Vertex AI ---\n",
    "import vertexai                                              # Importa el módulo principal de Vertex AI.\n",
    "from vertexai import init                                    # Inicializa Vertex AI con las credenciales y configuraciones necesarias.\n",
    "from vertexai.vision_models import MultiModalEmbeddingModel  # Importa el modelo de embeddings multimodales de Vertex AI para procesar imágenes y videos.\n",
    "from vertexai.vision_models import Video                     # Clase para manejar archivos de video en Vertex AI.\n",
    "from vertexai.vision_models import VideoSegmentConfig        # Configuración para segmentar videos al gener\n",
    "\n",
    "\n",
    "# --- Para conectarse y consultar un endpoint de búsqueda vectorial (Vector Search) en Vertex AI.\n",
    "from google.cloud.aiplatform.matching_engine import MatchingEngineIndexEndpoint \n",
    "\n",
    "# --- Para acceder a los buckets de Google Cloud Storage y manejar archivos.\n",
    "from google.cloud import storage\n",
    "\n",
    "\n",
    "# --- Dependencias para poder visualizar ---\n",
    "from IPython.display import Video as MVideo                  # Permite mostrar videos directamente en celdas de Jupyter Notebook.\n",
    "from IPython.display import HTML                             # Permite mostrar contenido HTML en celdas de Jupyter Notebook.\n",
    "from IPython.display import Image as ImageByte               # Permite mostrar imágenes en el notebook (renombrado como ImageByte para evitar conflictos de nombres).\n",
    "from IPython.display import display                          # Función general para mostrar objetos en el notebook.\n",
    "from sklearn.metrics.pairwise import cosine_similarity       # Función para calcular la similitud coseno entre vectores, útil para comparar embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fbd619",
   "metadata": {},
   "source": [
    "# **Configuración del entorno de Vertex**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d59658",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\")\n",
    "LOCATION = os.getenv(\"LOCATION\")\n",
    "INDEX_ENDPOINT_NAME = os.getenv(\"INDEX_ENDPOINT_NAME\")\n",
    "DEPLOYED_INDEX_ID = os.getenv(\"DEPLOYED_INDEX_ID\")\n",
    "BUCKET_NAME = os.getenv(\"BUCKET_NAME\")\n",
    "DESTINATION_BLOB_NAME = os.getenv(\"DESTINATION_BLOB_NAME\")\n",
    "\n",
    "print(\"PROJECT_ID:\", PROJECT_ID)\n",
    "print(\"INDEX_ENDPOINT_NAME:\", INDEX_ENDPOINT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5917d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ID: spry-byway-462510-i4\n",
      "LOCATION: us-west1\n"
     ]
    }
   ],
   "source": [
    "# Usamos las variables de entorno para cargar las credenciales de Vertex AI\n",
    "# load_dotenv()\n",
    "\n",
    "\n",
    "# --- Cargamos las credenciales de Vertex AI ---\n",
    "# PROJECT_ID = os.getenv(\"PROJECT_ID\")  \n",
    "PROJECT_ID = \"spry-byway-462510-i4\"\n",
    "# LOCATION = os.getenv(\"LOCATION\")\n",
    "LOCATION = \"us-west1\"\n",
    "\n",
    "print(\"PROJECT_ID:\", PROJECT_ID)\n",
    "print(\"LOCATION:\", LOCATION)\n",
    "\n",
    "\n",
    "\n",
    "# --- Inicializamos Vertex AI ---\n",
    "init(project = PROJECT_ID, location = LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5872b28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cargamos el modelo de embeddings multimodales ---\n",
    "mm_embendding_model = MultiModalEmbeddingModel.from_pretrained(\"multimodalembedding@001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a57b90a",
   "metadata": {},
   "source": [
    "# **Funciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08e114e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Función para generar embeddings de videos ---\n",
    "\n",
    "def get_video_embedding(ruta_video: str) -> list: \n",
    "    \n",
    "    \"\"\"\n",
    "    Genera un embedding para un video dado.\n",
    "\n",
    "    Args:\n",
    "        ruta_video (str): Ruta al archivo de video.\n",
    "\n",
    "    Returns:\n",
    "        list: Embedding del video.\n",
    "    \"\"\"\n",
    "    # Cargamos el video desde la ruta proporcionada\n",
    "    video = Video.load_from_file(ruta_video)\n",
    "    \n",
    "    # Genera el embedding del video utilizando el modelo de embeddings multimodales\n",
    "    embedding = mm_embendding_model.get_embeddings(video = video, \n",
    "                                                   video_segment_config = VideoSegmentConfig(interval_sec=4) # Configura el segmento del video para generar embeddings cada 4 segundos.\n",
    "                                                  )\n",
    "    \n",
    "    return [video_emb.embedding for video_emb in embedding.video_embeddings]  # Retorna una lista de embeddings para cada segmento del video.\n",
    "\n",
    "\n",
    "\n",
    "# --- Función para generar embeddings de texto ---\n",
    "\n",
    "def get_text_embedding(text: str) -> list:\n",
    "\n",
    "    print(f\"Generando embedding para el texto: '{text}'\")\n",
    "    embeddings = mm_embendding_model.get_embeddings(\n",
    "        contextual_text=text,\n",
    "    )\n",
    "\n",
    "    return embeddings.text_embedding\n",
    "\n",
    "\n",
    "\n",
    "# --- Función para buscar vecinos más cercanos en el índice de búsqueda vectorial --- \n",
    "\n",
    "def find_nearest_neighbors(query_embedding: list, num_neighbors: int = 8): # Cambia el número de vecinos a buscar según tus necesidades.\n",
    "\n",
    "    print(\"Conectando al Index Endpoint...\")\n",
    "    index_endpoint = MatchingEngineIndexEndpoint(index_endpoint_name=INDEX_ENDPOINT_NAME)\n",
    "    \n",
    "    print(f\"Buscando los {num_neighbors} videos más similares...\")\n",
    "    neighbors = index_endpoint.find_neighbors(\n",
    "\n",
    "        deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "        queries=[query_embedding],\n",
    "        num_neighbors=num_neighbors\n",
    "\n",
    "    )\n",
    "\n",
    "    return neighbors\n",
    "\n",
    "\n",
    "\n",
    "# --- Función para mostrar un segmento de video específico en el notebook ---\n",
    "\n",
    "def display_video_segment(video_gcs_uri: str, segment_id: str, interval: int):\n",
    "\n",
    "    try:\n",
    "        # Extraemos el número del segmento del ID. Ej: \"VIDEOYAGO_segment_5\" -> 5\n",
    "        segment_number = int(segment_id.split('_')[-1])\n",
    "        start_time = segment_number * interval # El intervalo (al menos en este notebook) es de 4 segundos.\n",
    "        end_time = start_time + interval\n",
    "        \n",
    "        # Convertimos la URI de gs:// a una URL pública de https://\n",
    "        public_url = video_gcs_uri.replace(\"gs://\", \"https://storage.googleapis.com/\")\n",
    "        \n",
    "        # Creamos el código HTML para el video, apuntando al tiempo de inicio\n",
    "        video_html = f\"\"\"\n",
    "        <p>Mostrando segmento: <b>{segment_id}</b> (segundos {start_time}-{end_time})</p>\n",
    "        <video width=\"640\" controls>\n",
    "            <source src=\"{public_url}#t={start_time},{end_time}\" type=\"video/mp4\">\n",
    "            Tu navegador no soporta la etiqueta de video.\n",
    "        </video>\n",
    "        \"\"\"\n",
    "        display(HTML(video_html))\n",
    "        \n",
    "    except (ValueError, IndexError) as e:\n",
    "        print(f\"No se pudo parsear el ID del segmento '{segment_id}'. Error: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Convierte una URI de Google Cloud Storage a una URL pública accesible por HTTP ---\n",
    "\n",
    "def get_public_url_from_gcs(gcs_uri: str) -> str:\n",
    "    \"\"\"\n",
    "    Convierte una URI de Google Cloud Storage (gs://bucket/archivo) a una URL pública HTTP.\n",
    "\n",
    "    Args:\n",
    "        gcs_uri (str): URI de Google Cloud Storage.\n",
    "\n",
    "    Returns:\n",
    "        str: URL pública accesible desde el navegador.\n",
    "    \"\"\"\n",
    "    return gcs_uri.replace(\"gs://\", \"https://storage.googleapis.com/\").replace(\n",
    "        \" \", \"%20\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# --- Muestra un video almacenado en Google Cloud Storage en el notebook ---\n",
    "\n",
    "def display_video_from_gcs(gcs_uri: str) -> None:\n",
    "    \"\"\"\n",
    "    Muestra un video almacenado en Google Cloud Storage directamente en el notebook.\n",
    "\n",
    "    Args:\n",
    "        gcs_uri (str): URI de Google Cloud Storage del video.\n",
    "    \"\"\"\n",
    "    public_url = get_public_url_from_gcs(gcs_uri)\n",
    "    display(\n",
    "        HTML(\n",
    "            f\"\"\"\n",
    "            <video width=\"480\" controls>\n",
    "                <source src=\"{public_url}\" type=\"video/mp4\">\n",
    "                Tu navegador no soporta la reproducción de video.\n",
    "            </video>\n",
    "            \"\"\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# --- Función para imprimir videos similares basados en embeddings ---\n",
    "\n",
    "def print_similar_videos(query_emb: list[float], data_frame: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Calcula la similitud (producto punto) entre un embedding de consulta y los embeddings de videos almacenados en un DataFrame.\n",
    "    Muestra los videos más similares y despliega el video más relevante en el notebook.\n",
    "\n",
    "    Args:\n",
    "        query_emb (list[float]): Embedding de consulta (por ejemplo, generado a partir de un video o texto).\n",
    "        data_frame (pd.DataFrame): DataFrame que contiene al menos las columnas 'video_embeddings', 'file_name' y 'gcs_path'.\n",
    "\n",
    "    Funcionamiento:\n",
    "        - Calcula el producto punto entre el embedding de consulta y cada embedding de video en el DataFrame.\n",
    "        - Añade una columna 'score' con los resultados de similitud.\n",
    "        - Ordena el DataFrame por 'score' de mayor a menor.\n",
    "        - Imprime los nombres de los archivos y sus scores más altos.\n",
    "        - Muestra el video más similar directamente en el notebook.\n",
    "    \"\"\"\n",
    "    # Obtiene la columna de embeddings de video\n",
    "    video_embs = data_frame[\"video_embeddings\"]\n",
    "\n",
    "    # Calcula el producto punto entre cada embedding y el de consulta\n",
    "    scores = [np.dot(eval(video_emb), query_emb) for video_emb in video_embs]\n",
    "    data_frame[\"score\"] = scores\n",
    "\n",
    "    # Ordena por score descendente\n",
    "    data_frame = data_frame.sort_values(by=\"score\", ascending=False)\n",
    "\n",
    "    # Imprime los resultados principales\n",
    "    print(data_frame.head()[[\"score\", \"file_name\"]])\n",
    "\n",
    "    # Obtiene la URL GCS del video más similar\n",
    "    url = data_frame.iloc[0][\"gcs_path\"]\n",
    "\n",
    "    # Muestra el video en el notebook\n",
    "    display_video_from_gcs(url)\n",
    "\n",
    "\n",
    "\n",
    "# --- Función para guardar embeddings en Google Cloud Storage como JSONL ---\n",
    "\n",
    "def guardar_embeddings_en_gcs(\n",
    "    project_id: str,\n",
    "    bucket_name: str,\n",
    "    blob_name: str,\n",
    "    ids: list[str],\n",
    "    embeddings: list[list[float]]\n",
    "):\n",
    "    \"\"\"\n",
    "    Convierte una lista de IDs y embeddings al formato JSONL y lo sube a GCS.\n",
    "\n",
    "    Args:\n",
    "        project_id (str): Tu proyecto de Google Cloud.\n",
    "        bucket_name (str): El nombre del bucket de destino.\n",
    "        blob_name (str): La ruta y nombre del archivo a crear en el bucket.\n",
    "        ids (list[str]): Lista de IDs únicos para cada embedding.\n",
    "        embeddings (list[list[float]]): La lista de vectores de embedding.\n",
    "    \"\"\"\n",
    "    print(f\"Conectando al bucket '{bucket_name}'...\")\n",
    "    storage_client = storage.Client(project=project_id)\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    print(f\"Escribiendo {len(ids)} embeddings en el archivo en memoria...\")\n",
    "    \n",
    "    # Usamos un context manager para escribir directamente al archivo en GCS\n",
    "    with blob.open(\"w\") as f:\n",
    "        for i, embedding in zip(ids, embeddings):\n",
    "            # Creamos el diccionario para la línea actual\n",
    "            data_point = {\"id\": i, \"embedding\": embedding}\n",
    "            # Lo convertimos a un string JSON y escribimos la línea en el archivo\n",
    "            f.write(json.dumps(data_point) + \"\\n\")\n",
    "\n",
    "    print(f\"¡Éxito! Archivo '{blob_name}' subido correctamente a 'gs://{bucket_name}/{blob_name}'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7296a3d3",
   "metadata": {},
   "source": [
    "# **Generamos los embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b892321",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionDenied",
     "evalue": "403 Permission 'aiplatform.endpoints.predict' denied on resource '//aiplatform.googleapis.com/projects/spry-byway-462510-i4/locations/us-west1/publishers/google/models/multimodalembedding@001' (or it may not exist). [reason: \"IAM_PERMISSION_DENIED\"\ndomain: \"aiplatform.googleapis.com\"\nmetadata {\n  key: \"resource\"\n  value: \"projects/spry-byway-462510-i4/locations/us-west1/publishers/google/models/multimodalembedding@001\"\n}\nmetadata {\n  key: \"permission\"\n  value: \"aiplatform.endpoints.predict\"\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31m_InactiveRpcError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Embeddings_OFF/.venv/lib/python3.13/site-packages/google/api_core/grpc_helpers.py:76\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Embeddings_OFF/.venv/lib/python3.13/site-packages/grpc/_channel.py:1181\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable.__call__\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1175\u001b[39m (\n\u001b[32m   1176\u001b[39m     state,\n\u001b[32m   1177\u001b[39m     call,\n\u001b[32m   1178\u001b[39m ) = \u001b[38;5;28mself\u001b[39m._blocking(\n\u001b[32m   1179\u001b[39m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[32m   1180\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Embeddings_OFF/.venv/lib/python3.13/site-packages/grpc/_channel.py:1006\u001b[39m, in \u001b[36m_end_unary_response_blocking\u001b[39m\u001b[34m(state, call, with_call, deadline)\u001b[39m\n\u001b[32m   1005\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1006\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[31m_InactiveRpcError\u001b[39m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.PERMISSION_DENIED\n\tdetails = \"Permission 'aiplatform.endpoints.predict' denied on resource '//aiplatform.googleapis.com/projects/spry-byway-462510-i4/locations/us-west1/publishers/google/models/multimodalembedding@001' (or it may not exist).\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv6:%5B2607:f8b0:4012:823::200a%5D:443 {grpc_status:7, grpc_message:\"Permission \\'aiplatform.endpoints.predict\\' denied on resource \\'//aiplatform.googleapis.com/projects/spry-byway-462510-i4/locations/us-west1/publishers/google/models/multimodalembedding@001\\' (or it may not exist).\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mPermissionDenied\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m ruta_video = \u001b[33m\"\u001b[39m\u001b[33mgs://vboxioof/Videos/azteca7-2025-05-23.mkv\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;66;03m# Ruta al video\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Generamos el embedding del video\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m video_embedding = \u001b[43mget_video_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruta_video\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mget_video_embedding\u001b[39m\u001b[34m(ruta_video)\u001b[39m\n\u001b[32m     15\u001b[39m video = Video.load_from_file(ruta_video)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Genera el embedding del video utilizando el modelo de embeddings multimodales\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m embedding = \u001b[43mmm_embendding_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m                                               \u001b[49m\u001b[43mvideo_segment_config\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mVideoSegmentConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterval_sec\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Configura el segmento del video para generar embeddings cada 4 segundos.\u001b[39;49;00m\n\u001b[32m     20\u001b[39m \u001b[43m                                              \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [video_emb.embedding \u001b[38;5;28;01mfor\u001b[39;00m video_emb \u001b[38;5;129;01min\u001b[39;00m embedding.video_embeddings]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Embeddings_OFF/.venv/lib/python3.13/site-packages/vertexai/vision_models/_vision_models.py:1275\u001b[39m, in \u001b[36mMultiModalEmbeddingModel.get_embeddings\u001b[39m\u001b[34m(self, image, video, contextual_text, dimension, video_segment_config)\u001b[39m\n\u001b[32m   1272\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dimension:\n\u001b[32m   1273\u001b[39m     parameters[\u001b[33m\"\u001b[39m\u001b[33mdimension\u001b[39m\u001b[33m\"\u001b[39m] = dimension\n\u001b[32m-> \u001b[39m\u001b[32m1275\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_endpoint\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1276\u001b[39m \u001b[43m    \u001b[49m\u001b[43minstances\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1277\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1278\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1279\u001b[39m image_embedding = response.predictions[\u001b[32m0\u001b[39m].get(\u001b[33m\"\u001b[39m\u001b[33mimageEmbedding\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1280\u001b[39m video_embeddings = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Embeddings_OFF/.venv/lib/python3.13/site-packages/google/cloud/aiplatform/models.py:2293\u001b[39m, in \u001b[36mEndpoint.predict\u001b[39m\u001b[34m(self, instances, parameters, timeout, use_raw_predict, use_dedicated_endpoint)\u001b[39m\n\u001b[32m   2284\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Prediction(\n\u001b[32m   2285\u001b[39m         predictions=prediction_response.get(\u001b[33m\"\u001b[39m\u001b[33mpredictions\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   2286\u001b[39m         metadata=prediction_response.get(\u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m   2289\u001b[39m         model_version_id=prediction_response.get(\u001b[33m\"\u001b[39m\u001b[33mmodelVersionId\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   2290\u001b[39m     )\n\u001b[32m   2292\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2293\u001b[39m     prediction_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prediction_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2294\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_gca_resource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2295\u001b[39m \u001b[43m        \u001b[49m\u001b[43minstances\u001b[49m\u001b[43m=\u001b[49m\u001b[43minstances\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2296\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2297\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2298\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2299\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m prediction_response._pb.metadata:\n\u001b[32m   2300\u001b[39m         metadata = json_format.MessageToDict(prediction_response._pb.metadata)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Embeddings_OFF/.venv/lib/python3.13/site-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py:887\u001b[39m, in \u001b[36mPredictionServiceClient.predict\u001b[39m\u001b[34m(self, request, endpoint, instances, parameters, retry, timeout, metadata)\u001b[39m\n\u001b[32m    884\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m    886\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m    895\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Embeddings_OFF/.venv/lib/python3.13/site-packages/google/api_core/gapic_v1/method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Embeddings_OFF/.venv/lib/python3.13/site-packages/google/api_core/grpc_helpers.py:78\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(*args, **kwargs)\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mPermissionDenied\u001b[39m: 403 Permission 'aiplatform.endpoints.predict' denied on resource '//aiplatform.googleapis.com/projects/spry-byway-462510-i4/locations/us-west1/publishers/google/models/multimodalembedding@001' (or it may not exist). [reason: \"IAM_PERMISSION_DENIED\"\ndomain: \"aiplatform.googleapis.com\"\nmetadata {\n  key: \"resource\"\n  value: \"projects/spry-byway-462510-i4/locations/us-west1/publishers/google/models/multimodalembedding@001\"\n}\nmetadata {\n  key: \"permission\"\n  value: \"aiplatform.endpoints.predict\"\n}\n]"
     ]
    }
   ],
   "source": [
    "ruta_video = \"gs://vboxioof/Videos/azteca7-2025-05-23.mkv\" # Ruta al video\n",
    "\n",
    "# Generamos el embedding del video\n",
    "video_embedding = get_video_embedding(ruta_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224aa148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vemos cuantos embeddings se generaron\n",
    "print(f\"Número de embeddings generados: {len(video_embedding)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280cf794",
   "metadata": {},
   "source": [
    "# **Carga a Vector Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9085a3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectando al bucket 'canalesparaprueba'...\n",
      "Escribiendo 8 embeddings en el archivo en memoria...\n",
      "¡Éxito! Archivo 'embeddings/video_embeddings_yago.json' subido correctamente a 'gs://canalesparaprueba/embeddings/video_embeddings_yago.json'.\n"
     ]
    }
   ],
   "source": [
    "INDEX_ENDPOINT_NAME = \"projects/144706985230/locations/us-central1/indexEndpoints/7120122841151832064\"\n",
    "DEPLOYED_INDEX_ID = \"embeddings_video_yago_prue_1749587612895\"\n",
    "BUCKET_NAME = \"canalesparaprueba\" #  Aquí era otro bucket, me equivoqué xd\n",
    "DESTINATION_BLOB_NAME = \"embeddings/video_embeddings_yago.json\" \n",
    "\n",
    "print(\"INDEX_ENDPOINT_NAME:\", INDEX_ENDPOINT_NAME)\n",
    "print(\"DEPLOYED_INDEX_ID:\", DEPLOYED_INDEX_ID)\n",
    "\n",
    "\n",
    "# --- GENERACIÓN DE IDs ---\n",
    "ids_de_embeddings = [f\"VIDEOYAGO_segment_{i}\" for i in range(len(video_embedding))]\n",
    "\n",
    "\n",
    "if len(ids_de_embeddings) != len(video_embedding):\n",
    "        raise ValueError(\"La cantidad de IDs no coincide con la cantidad de embeddings.\")\n",
    "        \n",
    "guardar_embeddings_en_gcs(\n",
    "    project_id=PROJECT_ID,\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    blob_name=DESTINATION_BLOB_NAME,\n",
    "    ids=ids_de_embeddings,\n",
    "    embeddings=video_embedding\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbf4e48",
   "metadata": {},
   "source": [
    "# **Query a los embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dc059d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando embedding para el texto: 'GOVI'\n",
      "Conectando al Index Endpoint...\n",
      "Buscando los 8 videos más similares...\n",
      "\n",
      "--- RESULTADOS DE LA BÚSQUEDA ---\n",
      "\n",
      "Encontrado: [ID: 3] - [Distancia: 0.0364]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Mostrando segmento: <b>3</b> (segundos 12-16)</p>\n",
       "        <video width=\"640\" controls>\n",
       "            <source src=\"https://storage.googleapis.com/borrar_valerio/VIDEOYAGO.mp4#t=12,16\" type=\"video/mp4\">\n",
       "            Tu navegador no soporta la etiqueta de video.\n",
       "        </video>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encontrado: [ID: 2] - [Distancia: 0.0346]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Mostrando segmento: <b>2</b> (segundos 8-12)</p>\n",
       "        <video width=\"640\" controls>\n",
       "            <source src=\"https://storage.googleapis.com/borrar_valerio/VIDEOYAGO.mp4#t=8,12\" type=\"video/mp4\">\n",
       "            Tu navegador no soporta la etiqueta de video.\n",
       "        </video>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encontrado: [ID: 1] - [Distancia: 0.0316]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Mostrando segmento: <b>1</b> (segundos 4-8)</p>\n",
       "        <video width=\"640\" controls>\n",
       "            <source src=\"https://storage.googleapis.com/borrar_valerio/VIDEOYAGO.mp4#t=4,8\" type=\"video/mp4\">\n",
       "            Tu navegador no soporta la etiqueta de video.\n",
       "        </video>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encontrado: [ID: 4] - [Distancia: 0.0254]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Mostrando segmento: <b>4</b> (segundos 16-20)</p>\n",
       "        <video width=\"640\" controls>\n",
       "            <source src=\"https://storage.googleapis.com/borrar_valerio/VIDEOYAGO.mp4#t=16,20\" type=\"video/mp4\">\n",
       "            Tu navegador no soporta la etiqueta de video.\n",
       "        </video>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encontrado: [ID: 0] - [Distancia: 0.0243]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Mostrando segmento: <b>0</b> (segundos 0-4)</p>\n",
       "        <video width=\"640\" controls>\n",
       "            <source src=\"https://storage.googleapis.com/borrar_valerio/VIDEOYAGO.mp4#t=0,4\" type=\"video/mp4\">\n",
       "            Tu navegador no soporta la etiqueta de video.\n",
       "        </video>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# La ruta original de tu video. La necesitamos para poder mostrar el fragmento.\n",
    "GCS_VIDEO_URI = \"gs://borrar_valerio/VIDEOYAGO.mp4\"\n",
    "SEGMENT_INTERVAL_SEC = 4 # El intervalo en segundos que usaste para segmentar el video\n",
    "\n",
    "# --- INICIALIZACIÓN Y MODELOS ---\n",
    "# Asumo que vertexai.init() ya se ejecutó.\n",
    "# Creamos una instancia del modelo de embedding para usarlo en la función de texto.\n",
    "\n",
    "\n",
    "\n",
    "# --- EJECUCIÓN DE LA BÚSQUEDA ---\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # AQUÍ PONES TU CONSULTA EN LENGUAJE NATURAL\n",
    "    texto_de_busqueda = \"GOVI\"\n",
    "    # ------------------------------------------------------------------\n",
    "    \n",
    "    # 1. Obtenemos el embedding del texto de búsqueda\n",
    "    query_emb = get_text_embedding(texto_de_busqueda)\n",
    "    \n",
    "    # 2. Buscamos en Vector Search usando el embedding del texto\n",
    "    search_results = find_nearest_neighbors(query_emb)\n",
    "    \n",
    "    # 3. Mostramos los resultados\n",
    "    print(\"\\n--- RESULTADOS DE LA BÚSQUEDA ---\")\n",
    "    \n",
    "    if not search_results or not search_results[0]:\n",
    "        print(\"No se encontraron resultados.\")\n",
    "    else:\n",
    "        for neighbor in search_results[0]:\n",
    "            video_segment_id = neighbor.id\n",
    "            distancia = neighbor.distance\n",
    "            print(f\"\\nEncontrado: [ID: {video_segment_id}] - [Distancia: {distancia:.8f}]\")\n",
    "            \n",
    "            # Mostramos el fragmento de video correspondiente\n",
    "            display_video_segment(\n",
    "                video_gcs_uri=GCS_VIDEO_URI,\n",
    "                segment_id=video_segment_id,\n",
    "                interval=SEGMENT_INTERVAL_SEC\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
