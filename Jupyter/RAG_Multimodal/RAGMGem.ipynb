{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f30e6a11",
   "metadata": {},
   "source": [
    "# **Importamos las dependencias**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d938dfe",
   "metadata": {},
   "source": [
    "Estoy importando todas las dependencias de mis cuadernos, despues las depuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "738a5349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Importaciones para Manejo de Archivos y Directorios ---\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "import math\n",
    "\n",
    "# --- Importamos Vertex AI ---\n",
    "import vertexai\n",
    "\n",
    "\n",
    "# --- Importaciones para Visualización y Formato de Texto ---\n",
    "\n",
    "# Se utiliza para mostrar contenido enriquecido, como texto con formato Markdown,\n",
    "# directamente en entornos como Jupyter Notebooks o IPython.\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Importa la clase `Markdown` de la biblioteca `rich`, que sirve para renderizar\n",
    "# Markdown con formato avanzado en la terminal. Se le da un alias `RichMarkdown`\n",
    "# para evitar conflictos de nombre con la importación anterior.\n",
    "from rich.markdown import Markdown as RichMarkdown\n",
    "\n",
    "\n",
    "# --- Importaciones para el Modelo Generativo de Vertex AI ---\n",
    "\n",
    "# Importa las clases necesarias del SDK de Vertex AI para interactuar con los modelos generativos.\n",
    "# - GenerationConfig: Para configurar los parámetros de la respuesta (ej. temperatura, top_p).\n",
    "# - GenerativeModel: La clase principal para cargar y usar un modelo generativo como Gemini.\n",
    "# - Image: Para manejar y enviar imágenes como parte de la entrada al modelo (enfoque multimodal).\n",
    "from vertexai.generative_models import GenerationConfig, GenerativeModel, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81a731d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Para el proceso de datos y visualización ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "\n",
    "# --- Para manejar las variables de entorno ---\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# --- Desactiva las advertencias de asignaciones encadenadas en pandas para evitar mensajes de warning al modificar DataFrames.\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "\n",
    "# --- Dependencias de Vertex AI ---\n",
    "import vertexai                                              # Importa el módulo principal de Vertex AI.\n",
    "from vertexai import init                                    # Inicializa Vertex AI con las credenciales y configuraciones necesarias.\n",
    "from vertexai.vision_models import Image as VMImage          # Importa la clase Image de Vertex AI para manejar imágenes.\n",
    "from vertexai.vision_models import MultiModalEmbeddingModel  # Importa el modelo de embeddings multimodales de Vertex AI para procesar imágenes y videos.\n",
    "from vertexai.vision_models import Video                     # Clase para manejar archivos de video en Vertex AI.\n",
    "from vertexai.vision_models import VideoSegmentConfig        # Configuración para segmentar videos\n",
    "from vertexai.generative_models import GenerativeModel       # Importa la clase para modelos generativos, como Gemini.\n",
    "from vertexai.generative_models import Part                  # Importa la clase Part para manejar partes de un mensaje, como texto o imágenes.\n",
    "\n",
    "\n",
    "# --- Para conectarse y consultar un endpoint de búsqueda vectorial (Vector Search) en Vertex AI. \n",
    "from google.cloud.aiplatform.matching_engine import MatchingEngineIndexEndpoint \n",
    "\n",
    "# --- Para acceder a los buckets de Google Cloud Storage y manejar archivos.\n",
    "from google.cloud import storage\n",
    "\n",
    "\n",
    "# --- Dependencias para poder visualizar ---\n",
    "from IPython.display import Video as MVideo                  # Permite mostrar videos directamente en celdas de Jupyter Notebook.\n",
    "from IPython.display import HTML                             # Permite mostrar contenido HTML en celdas de Jupyter Notebook.\n",
    "from IPython.display import Image as ImageByte               # Permite mostrar imágenes en el notebook (renombrado como ImageByte para evitar conflictos de nombres).\n",
    "from IPython.display import display                          # Función general para mostrar objetos en el notebook.\n",
    "from sklearn.metrics.pairwise import cosine_similarity       # Función para calcular la similitud coseno entre vectores, útil para comparar embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628156ac",
   "metadata": {},
   "source": [
    "# **Configuración de credenciales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "403e2df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python-dotenv could not parse statement starting at line 3\n",
      "python-dotenv could not parse statement starting at line 4\n",
      "python-dotenv could not parse statement starting at line 5\n",
      "python-dotenv could not parse statement starting at line 7\n",
      "python-dotenv could not parse statement starting at line 15\n",
      "python-dotenv could not parse statement starting at line 16\n",
      "python-dotenv could not parse statement starting at line 17\n",
      "python-dotenv could not parse statement starting at line 19\n",
      "python-dotenv could not parse statement starting at line 28\n",
      "python-dotenv could not parse statement starting at line 29\n",
      "python-dotenv could not parse statement starting at line 30\n",
      "python-dotenv could not parse statement starting at line 32\n",
      "python-dotenv could not parse statement starting at line 33\n"
     ]
    }
   ],
   "source": [
    "# --- Carga las Variables de Entorno ---\n",
    "load_dotenv()\n",
    "\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\")                        # ID del proyecto de Google Cloud\n",
    "LOCATION = os.getenv(\"LOCATION\")                            # Región donde se encuentran los recursos de Vertex AI\n",
    "INDEX_ID = os.getenv(\"INDEX_ID\")                            # ID del índice de búsqueda vectorial en Vertex AI\n",
    "ENDPOINT_ID = os.getenv(\"ENDPOINT_ID\")                      # ID del endpoint de búsqueda vectorial en Vertex AI\n",
    "BUCKET_NAME = os.getenv(\"BUCKET_NAME\")                      # Nombre del bucket de Google Cloud Storage donde se almacenan los videos\n",
    "VIDEO_FOLDER_PATH = os.getenv(\"VIDEO_FOLDER_PATH\")          # Ruta del folder dentro del bucket donde se encuentran los videos\n",
    "\n",
    "# Verificamos que las variebles de entorno esten bien\n",
    "# print(f\"Proyecto: {PROJECT_ID}, Ubicación: {LOCATION}, Índice: {INDEX_ID}, Endpoint: {ENDPOINT_ID}, Bucket: {BUCKET_NAME}, Ruta de Videos: {VIDEO_FOLDER_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb909a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciamos Vertex AI con el proyecto y la ubicación especificados.\n",
    "init(project = PROJECT_ID, location = LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f569329e",
   "metadata": {},
   "source": [
    "# **Configuración de Vertex AI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d06bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inicialización del LLM ---\n",
    "model = GenerativeModel('gemini-2.5-flash-lite-preview-06-17') # Debo probar con varios modelos, para ver cual tiene mejor rendimiento.\n",
    "\n",
    "# --- Carga del Modelo de Embeddings Multimodal ---\n",
    "embedding_model = MultiModalEmbeddingModel.from_pretrained(\"multimodalembedding@001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15024b8f",
   "metadata": {},
   "source": [
    "# **Funciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "957b17d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Para hacerle embeddings a un determinado texto ---\n",
    "\n",
    "def text_embedding(text):\n",
    "    \"\"\"\n",
    "    Función para obtener el embedding de un texto utilizando el modelo de embeddings multimodal.\n",
    "\n",
    "    Args:\n",
    "        text (str): El texto del cual se desea obtener el embedding.\n",
    "\n",
    "    Returns:\n",
    "        list: Un vector de embedding que representa el texto.\n",
    "    \"\"\"\n",
    "    embedding = embedding_model.get_embeddings(contextual_text=text)\n",
    "\n",
    "    return embedding.text_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "694a5f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Función para buscar los embeddings mas cercanos ---\n",
    "\n",
    "def busqueda_vectorial(emb, res = 5):\n",
    "    \"\"\"\n",
    "    Realiza una búsqueda vectorial utilizando un texto de consulta y devuelve los resultados más relevantes.\n",
    "\n",
    "    Args:\n",
    "        emb (list): Lista de embeddings del texto de consulta.\n",
    "        res (int): Número de resultados a devolver. Por defecto es 5.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista de resultados relevantes encontrados en el índice.\n",
    "    \"\"\"\n",
    "\n",
    "    print('Nos conectamos al endpoint del índice de búsqueda vectorial...')\n",
    "    index_endpoint = MatchingEngineIndexEndpoint(index_endpoint_name = INDEX_ID)\n",
    "\n",
    "    print(f'Buscando los {res} resultados más relevantes para la consulta...')\n",
    "    query = index_endpoint.find_neighbors(\n",
    "\n",
    "        deployed_index_id=ENDPOINT_ID,  # ID del índice desplegado\n",
    "        queries=[emb],                  # Lista de embeddings de consulta\n",
    "        num_neighbors=res               # Número de vecinos a devolver\n",
    "\n",
    "    )\n",
    "\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ca4ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Función para obtener el nombre del clip a partír de los índices de una consulta ---\n",
    "\n",
    "def get_clip_name(lista):\n",
    "    \"\"\"\n",
    "    La función de 'busqueda_vectorial' nos devuelve una lista de índices, aquí construímos los nombres\n",
    "    de los respectivos clips de esos segmentos\n",
    "    \n",
    "    Args:\n",
    "        lista (list): Lista de índices.\n",
    "\n",
    "    Returns:\n",
    "        lista (list): Lista del nombre de los clips, ordenada por el número de clip\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    nombres_de_videos = []\n",
    "\n",
    "    for item in lista:\n",
    "\n",
    "        # Extraemos el número del índice\n",
    "        num = int(re.search(r'\\d+', item.id).group())\n",
    "\n",
    "        # Encontramos el número de clip\n",
    "        numero_de_clip = math.floor(num / 4)\n",
    "\n",
    "        # Construimos el nombre del video\n",
    "        def nombre_clip(n):\n",
    "            if len(str(n)) == 1:\n",
    "                return f'mexicosta_segment_00{n}.mkv'\n",
    "            elif len(str(n)) == 2:\n",
    "                return f'mexicosta_segment_0{n}.mkv'\n",
    "            else:\n",
    "                return f'mexicosta_segment_{n}.mkv'\n",
    "\n",
    "        # Si la división no es exacta, agregamos el clip actual y el siguiente\n",
    "        if num % 4 != 0:\n",
    "            nombre_actual = nombre_clip(numero_de_clip)\n",
    "            nombre_siguiente = nombre_clip(numero_de_clip + 1)\n",
    "            nombres_de_videos.append(nombre_actual)\n",
    "            nombres_de_videos.append(nombre_siguiente)\n",
    "        else:\n",
    "            nombre_actual = nombre_clip(numero_de_clip)\n",
    "            nombres_de_videos.append(nombre_actual)\n",
    "\n",
    "\n",
    "        # Quitamos los repetidos en la lista\n",
    "        nombres_de_videos = set(nombres_de_videos)\n",
    "        nombres_de_videos = list(nombres_de_videos)\n",
    "\n",
    "    return sorted(\n",
    "        nombres_de_videos,\n",
    "        key = lambda x: int(re.search(r'(\\d+)', x).group())\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125ea1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Función para reconstruír la url pública\n",
    "\n",
    "def get_public_url_from_gcs(gcs_uri: str) -> str:\n",
    "    \"\"\"\n",
    "    Convierte una URI de Google Cloud Storage (gs://bucket/archivo) a una URL pública HTTP.\n",
    "\n",
    "    Args:\n",
    "        gcs_uri (str): URI de Google Cloud Storage.\n",
    "\n",
    "    Returns:\n",
    "        str: URL pública accesible desde el navegador.\n",
    "    \"\"\"\n",
    "    return gcs_uri.replace(\"gs://\", \"https://storage.googleapis.com/\").replace(\n",
    "        \" \", \"%20\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "84b1f799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_videos_similares(texto_de_la_pregunta, cantidad_de_resultados=5):\n",
    "\n",
    "    \"\"\"\n",
    "    Hacemos el embedding de la pregunta, y buscamos en Vector Search los videos más similares.\n",
    "    Devolvemos las URIs de los videos encontrados.\n",
    "\n",
    "    Args:\n",
    "        texto_de_la_pregunta (str): La pregunta o consulta para buscar videos similares.\n",
    "        cantidad_de_resultados (int): Número de resultados a devolver. Por defecto es 5.\n",
    "\n",
    "    Returns:\n",
    "        list: Una lista de URIs de los videos encontrados que son similares a la pregunta.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    print(f'--- 1.- Hacemos el embedding de la pregunta: {texto_de_la_pregunta} ---')\n",
    "\n",
    "    # Hacemos el embedding de la pregunta\n",
    "    try:\n",
    "        vector_de_la_pregunta = text_embedding(texto_de_la_pregunta)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Error al hacer el embedding de la pregunta: {e}')\n",
    "        return []\n",
    "    \n",
    "    print('Fin del paso 1.\\n')\n",
    "    \n",
    "\n",
    "\n",
    "    print(f'\\n --- 2.- Nos conectamos a Vector Search ---')\n",
    "\n",
    "    index_endpoint = MatchingEngineIndexEndpoint(\n",
    "        INDEX_ID\n",
    "    )\n",
    "\n",
    "    print('Fin del paso 2.\\n')\n",
    "\n",
    "\n",
    "\n",
    "    print(f'\\n --- 3.- Buscamos los {cantidad_de_resultados} videos más similares a la pregunta ---')\n",
    "\n",
    "    try:\n",
    "        # Buscamos usando la técnica de 'nearest neighbors'\n",
    "        response = busqueda_vectorial(\n",
    "            emb=vector_de_la_pregunta,         # Usamos el embedding de la pregunta\n",
    "            res=cantidad_de_resultados         # Número de vecinos a buscar\n",
    "        )\n",
    "\n",
    "        print(f'Obtuvimos los siguientes índices:\\n {response}')\n",
    "\n",
    "        # Extraemos las URIs de los videos encontrados\n",
    "        uris_completas = []\n",
    "\n",
    "        if response and response[0]:\n",
    "            for neighbor in response[0]:\n",
    "                segment_id_base = neighbor.id # Nos da por ejemplo: \"mexicosta_segment_1\"\n",
    "\n",
    "                # Extraemos el prefijo y el número del ID\n",
    "                match = re.match(r\"(.*_)(\\d+)\", segment_id_base)\n",
    "                if match:\n",
    "                    prefijo = match.group(1) # \"mexicosta_segment_\"\n",
    "                    numero = match.group(2)  # \"1\" \n",
    "                    \n",
    "                    # Formateamos el número a 3 dígitos con ceros a la izquierda (ej. \"001\")\n",
    "                    numero_formateado = numero.zfill(3)\n",
    "                    \n",
    "                    # Reconstruimos el nombre del archivo final\n",
    "                    nombre_archivo_final = f\"{prefijo}{numero_formateado}\"\n",
    "                    \n",
    "                    # Creamos la URI completa con la extensión .mkv\n",
    "                    uri = f\"gs://{BUCKET_NAME}/{VIDEO_FOLDER_PATH}/{nombre_archivo_final}.mkv\"\n",
    "                    uris_completas.append(uri)\n",
    "                \n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'Error al buscar los videos similares: {e}')\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7156d451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_fragmentos_con_gemini(\n",
    "    pregunta_original: str,\n",
    "    uris_de_videos: list[str] ) -> str:\n",
    "\n",
    "    \"\"\"\n",
    "    Toma la pregunta y una lista de URIs de video, las envía a Gemini\n",
    "    y devuelve la respuesta generada por el modelo.\n",
    "    \"\"\"\n",
    "    if not uris_de_videos:\n",
    "        return \"No se encontraron videos relevantes para analizar.\"\n",
    "\n",
    "    print(f\"\\nPASO 3.1: Preparando {len(uris_de_videos)} videos para enviar a Gemini...\")\n",
    "    \n",
    "    # Convertimos cada URI de video en un objeto 'Part' que Gemini entiende\n",
    "    video_parts = [Part.from_uri(uri, mime_type=\"video/mkv\") for uri in uris_de_videos]\n",
    "\n",
    "    # Construimos el prompt para el modelo\n",
    "    prompt_completo = [\n",
    "        \"Eres un asistente experto en análisis de video.\",\n",
    "        \"Tu tarea es analizar los siguientes fragmentos de video que te proporciono y responder a la pregunta del usuario de la forma más detallada posible basándote ÚNICAMENTE en el contenido de estos videos.\",\n",
    "        \"\\n---\",\n",
    "        \"PREGUNTA DEL USUARIO:\",\n",
    "        pregunta_original,\n",
    "        \"\\n---\",\n",
    "        \"FRAGMENTOS DE VIDEO A ANALIZAR:\",\n",
    "        *video_parts\n",
    "    ]\n",
    "\n",
    "    print(\"PASO 3.2: Enviando la solicitud a Gemini... (Esto puede tardar un poco)\")\n",
    "    try:\n",
    "        # Enviamos el prompt completo al modelo generativo\n",
    "        response = model.generate_content(prompt_completo)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Ocurrió un error al contactar con el modelo Gemini: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1924493a",
   "metadata": {},
   "source": [
    "# **Pruebas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9dcfe01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INICIANDO PROCESO DE RAG MULTIMODAL ---\n",
      "\n",
      "\n",
      "--- 1.- Hacemos el embedding de la pregunta: Caliente ---\n",
      "Fin del paso 1.\n",
      "\n",
      "\n",
      " --- 2.- Nos conectamos a Vector Search ---\n",
      "Fin del paso 2.\n",
      "\n",
      "\n",
      " --- 3.- Buscamos los 10 videos más similares a la pregunta ---\n",
      "Nos conectamos al endpoint del índice de búsqueda vectorial...\n",
      "Buscando los 10 resultados más relevantes para la consulta...\n",
      "Obtuvimos los siguientes índices:\n",
      " [[MatchNeighbor(id='mexicosta_segment_1090', distance=0.14725038409233093, sparse_distance=None, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]), MatchNeighbor(id='mexicosta_segment_162', distance=0.14469942450523376, sparse_distance=None, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]), MatchNeighbor(id='mexicosta_segment_905', distance=0.13280153274536133, sparse_distance=None, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]), MatchNeighbor(id='mexicosta_segment_1095', distance=0.13174454867839813, sparse_distance=None, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]), MatchNeighbor(id='mexicosta_segment_167', distance=0.128984734416008, sparse_distance=None, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]), MatchNeighbor(id='mexicosta_segment_906', distance=0.12516272068023682, sparse_distance=None, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]), MatchNeighbor(id='mexicosta_segment_909', distance=0.11934281885623932, sparse_distance=None, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]), MatchNeighbor(id='mexicosta_segment_1025', distance=0.11447043716907501, sparse_distance=None, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]), MatchNeighbor(id='mexicosta_segment_166', distance=0.11340729892253876, sparse_distance=None, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]), MatchNeighbor(id='mexicosta_segment_1088', distance=0.1111026257276535, sparse_distance=None, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[])]]\n",
      "\n",
      "--- RESPUESTA FINAL DE GEMINI ---\n",
      "No se encontraron videos relevantes para analizar.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    pregunta_del_usuario = \"Caliente\"\n",
    "    print(\"--- INICIANDO PROCESO DE RAG MULTIMODAL ---\\n\\n\")\n",
    "    uris_relevantes = buscar_videos_similares(pregunta_del_usuario, 10)\n",
    "    respuesta_final = analizar_fragmentos_con_gemini(pregunta_del_usuario, uris_relevantes)\n",
    "    print(\"\\n--- RESPUESTA FINAL DE GEMINI ---\")\n",
    "    print(respuesta_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1baccb",
   "metadata": {},
   "source": [
    "# **Borrar**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
