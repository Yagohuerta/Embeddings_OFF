{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ce26080",
   "metadata": {},
   "source": [
    "# **Importamos las dependencias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98ed9793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: google-cloud-aiplatform 1.71.1 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Instalación de todas las dependencias necesarias\n",
    "%pip install google-cloud-storage google-cloud-aiplatform vertexai matplotlib seaborn scikit-learn pandas seaborn numpy python-dotenv --quiet\n",
    "%pip install python-dotenv --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d508109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Para el proceso de datos y visualización ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# --- Para manejar las variables de entorno ---\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# --- Desactiva las advertencias de asignaciones encadenadas en pandas para evitar mensajes de warning al modificar DataFrames.\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "\n",
    "# --- Dependencias de Vertex AI ---\n",
    "import vertexai                                              # Importa el módulo principal de Vertex AI.\n",
    "from vertexai import init                                    # Inicializa Vertex AI con las credenciales y configuraciones necesarias.\n",
    "from vertexai.vision_models import MultiModalEmbeddingModel  # Importa el modelo de embeddings multimodales de Vertex AI para procesar imágenes y videos.\n",
    "from vertexai.vision_models import Video                     # Clase para manejar archivos de video en Vertex AI.\n",
    "from vertexai.vision_models import VideoSegmentConfig        # Configuración para segmentar videos al gener\n",
    "\n",
    "\n",
    "# --- Para conectarse y consultar un endpoint de búsqueda vectorial (Vector Search) en Vertex AI.\n",
    "from google.cloud.aiplatform.matching_engine import MatchingEngineIndexEndpoint \n",
    "\n",
    "# --- Para acceder a los buckets de Google Cloud Storage y manejar archivos.\n",
    "from google.cloud import storage\n",
    "\n",
    "\n",
    "# --- Dependencias para poder visualizar ---\n",
    "from IPython.display import Video as MVideo                  # Permite mostrar videos directamente en celdas de Jupyter Notebook.\n",
    "from IPython.display import HTML                             # Permite mostrar contenido HTML en celdas de Jupyter Notebook.\n",
    "from IPython.display import Image as ImageByte               # Permite mostrar imágenes en el notebook (renombrado como ImageByte para evitar conflictos de nombres).\n",
    "from IPython.display import display                          # Función general para mostrar objetos en el notebook.\n",
    "from sklearn.metrics.pairwise import cosine_similarity       # Función para calcular la similitud coseno entre vectores, útil para comparar embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fbd619",
   "metadata": {},
   "source": [
    "# **Configuración del entorno de Vertex**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8d59658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ID: spry-byway-462510-i4\n",
      "INDEX_ENDPOINT_NAME: projects/123459559103/locations/us-west1/indexEndpoints/6122846003549700096\n",
      "DEPLOYED_INDEX_ID: grabacion_3gb_1749804060857\n",
      "BUCKET_NAME: vboxioof\n",
      "DESTINATION_BLOB_NAME: vboxioof/Embbedings\n"
     ]
    }
   ],
   "source": [
    "# --- Carga las variables de entorno desde un archivo .env ---\n",
    "load_dotenv()\n",
    "\n",
    "# --- Obtenemos las variables necesarias del entorno ---\n",
    "\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\")                        # ID del proyecto de Google Cloud\n",
    "LOCATION = os.getenv(\"LOCATION\")                            # Región donde se encuentran los recursos de Vertex AI\n",
    "INDEX_ENDPOINT_NAME = os.getenv(\"INDEX_ENDPOINT_NAME\")      # Nombre completo del endpoint de búsqueda vectorial\n",
    "DEPLOYED_INDEX_ID = os.getenv(\"DEPLOYED_INDEX_ID\")          # ID del índice desplegado en el endpoint\n",
    "BUCKET_NAME = os.getenv(\"BUCKET_NAME\")                      # Nombre del bucket de Google Cloud Storage\n",
    "DESTINATION_BLOB_NAME = os.getenv(\"DESTINATION_BLOB_NAME\")  # Ruta y nombre del archivo destino en el bucket\n",
    "\n",
    "# Imprime las variables cargadas para verificación (de si lo hicimos bien todo)\n",
    "print(\"PROJECT_ID:\", PROJECT_ID)\n",
    "print(\"INDEX_ENDPOINT_NAME:\", INDEX_ENDPOINT_NAME)\n",
    "print(\"DEPLOYED_INDEX_ID:\", DEPLOYED_INDEX_ID)\n",
    "print(\"BUCKET_NAME:\", BUCKET_NAME)\n",
    "print(\"DESTINATION_BLOB_NAME:\", DESTINATION_BLOB_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5917d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inicializamos Vertex AI ---\n",
    "init(project = PROJECT_ID, location = LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a57b90a",
   "metadata": {},
   "source": [
    "# **Funciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08e114e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Función para generar embeddings de videos ---\n",
    "\n",
    "def get_video_embedding(ruta_video: str) -> list: \n",
    "    \n",
    "    \"\"\"\n",
    "    Genera un embedding para un video dado.\n",
    "\n",
    "    Args:\n",
    "        ruta_video (str): Ruta al archivo de video.\n",
    "\n",
    "    Returns:\n",
    "        list: Embedding del video.\n",
    "    \"\"\"\n",
    "    # Cargamos el video desde la ruta proporcionada\n",
    "    video = Video.load_from_file(ruta_video)\n",
    "    \n",
    "    # Genera el embedding del video utilizando el modelo de embeddings multimodales\n",
    "    embedding = mm_embendding_model.get_embeddings(video = video, \n",
    "                                                   video_segment_config = VideoSegmentConfig(interval_sec=4) # Configura el segmento del video para generar embeddings cada 4 segundos.\n",
    "                                                  )\n",
    "    \n",
    "    return [video_emb.embedding for video_emb in embedding.video_embeddings]  # Retorna una lista de embeddings para cada segmento del video.\n",
    "\n",
    "\n",
    "\n",
    "# --- Función para generar embeddings de texto ---\n",
    "\n",
    "def get_text_embedding(text: str) -> list:\n",
    "\n",
    "    print(f\"Generando embedding para el texto: '{text}'\")\n",
    "    embeddings = mm_embendding_model.get_embeddings(\n",
    "        contextual_text=text,\n",
    "    )\n",
    "\n",
    "    return embeddings.text_embedding\n",
    "\n",
    "\n",
    "\n",
    "# --- Función para buscar vecinos más cercanos en el índice de búsqueda vectorial --- \n",
    "\n",
    "def find_nearest_neighbors(query_embedding: list, num_neighbors: int = 20): # Cambia el número de vecinos a buscar según tus necesidades.\n",
    "\n",
    "    print(\"Conectando al Index Endpoint...\")\n",
    "    index_endpoint = MatchingEngineIndexEndpoint(index_endpoint_name=INDEX_ENDPOINT_NAME)\n",
    "    \n",
    "    print(f\"Buscando los {num_neighbors} videos más similares...\")\n",
    "    neighbors = index_endpoint.find_neighbors(\n",
    "\n",
    "        deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "        queries=[query_embedding],\n",
    "        num_neighbors=num_neighbors\n",
    "\n",
    "    )\n",
    "\n",
    "    return neighbors\n",
    "\n",
    "\n",
    "\n",
    "# --- Función para mostrar un segmento de video específico en el notebook ---\n",
    "\n",
    "def display_video_segment(video_gcs_uri: str, segment_id: str, interval: int):\n",
    "\n",
    "    try:\n",
    "        # Extraemos el número del segmento del ID. Ej: \"VIDEOYAGO_segment_5\" -> 5\n",
    "        segment_number = int(segment_id.split('_')[-1])\n",
    "        start_time = segment_number * interval # El intervalo (al menos en este notebook) es de 4 segundos.\n",
    "        end_time = start_time + interval\n",
    "        \n",
    "        # Convertimos la URI de gs:// a una URL pública de https://\n",
    "        public_url = video_gcs_uri.replace(\"gs://\", \"https://storage.googleapis.com/\")\n",
    "        \n",
    "        # Creamos el código HTML para el video, apuntando al tiempo de inicio\n",
    "        video_html = f\"\"\"\n",
    "        <p>Mostrando segmento: <b>{segment_id}</b> (segundos {start_time}-{end_time})</p>\n",
    "        <video width=\"640\" controls>\n",
    "            <source src=\"{public_url}#t={start_time},{end_time}\" type=\"video/mp4\">\n",
    "            Tu navegador no soporta la etiqueta de video.\n",
    "        </video>\n",
    "        \"\"\"\n",
    "        display(HTML(video_html))\n",
    "        \n",
    "    except (ValueError, IndexError) as e:\n",
    "        print(f\"No se pudo parsear el ID del segmento '{segment_id}'. Error: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Convierte una URI de Google Cloud Storage a una URL pública accesible por HTTP ---\n",
    "\n",
    "def get_public_url_from_gcs(gcs_uri: str) -> str:\n",
    "    \"\"\"\n",
    "    Convierte una URI de Google Cloud Storage (gs://bucket/archivo) a una URL pública HTTP.\n",
    "\n",
    "    Args:\n",
    "        gcs_uri (str): URI de Google Cloud Storage.\n",
    "\n",
    "    Returns:\n",
    "        str: URL pública accesible desde el navegador.\n",
    "    \"\"\"\n",
    "    return gcs_uri.replace(\"gs://\", \"https://storage.googleapis.com/\").replace(\n",
    "        \" \", \"%20\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# --- Muestra un video almacenado en Google Cloud Storage en el notebook ---\n",
    "\n",
    "def display_video_from_gcs(gcs_uri: str) -> None:\n",
    "    \"\"\"\n",
    "    Muestra un video almacenado en Google Cloud Storage directamente en el notebook.\n",
    "\n",
    "    Args:\n",
    "        gcs_uri (str): URI de Google Cloud Storage del video.\n",
    "    \"\"\"\n",
    "    public_url = get_public_url_from_gcs(gcs_uri)\n",
    "    display(\n",
    "        HTML(\n",
    "            f\"\"\"\n",
    "            <video width=\"480\" controls>\n",
    "                <source src=\"{public_url}\" type=\"video/mp4\">\n",
    "                Tu navegador no soporta la reproducción de video.\n",
    "            </video>\n",
    "            \"\"\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# --- Función para imprimir videos similares basados en embeddings ---\n",
    "\n",
    "def print_similar_videos(query_emb: list[float], data_frame: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Calcula la similitud (producto punto) entre un embedding de consulta y los embeddings de videos almacenados en un DataFrame.\n",
    "    Muestra los videos más similares y despliega el video más relevante en el notebook.\n",
    "\n",
    "    Args:\n",
    "        query_emb (list[float]): Embedding de consulta (por ejemplo, generado a partir de un video o texto).\n",
    "        data_frame (pd.DataFrame): DataFrame que contiene al menos las columnas 'video_embeddings', 'file_name' y 'gcs_path'.\n",
    "\n",
    "    Funcionamiento:\n",
    "        - Calcula el producto punto entre el embedding de consulta y cada embedding de video en el DataFrame.\n",
    "        - Añade una columna 'score' con los resultados de similitud.\n",
    "        - Ordena el DataFrame por 'score' de mayor a menor.\n",
    "        - Imprime los nombres de los archivos y sus scores más altos.\n",
    "        - Muestra el video más similar directamente en el notebook.\n",
    "    \"\"\"\n",
    "    # Obtiene la columna de embeddings de video\n",
    "    video_embs = data_frame[\"video_embeddings\"]\n",
    "\n",
    "    # Calcula el producto punto entre cada embedding y el de consulta\n",
    "    scores = [np.dot(eval(video_emb), query_emb) for video_emb in video_embs]\n",
    "    data_frame[\"score\"] = scores\n",
    "\n",
    "    # Ordena por score descendente\n",
    "    data_frame = data_frame.sort_values(by=\"score\", ascending=False)\n",
    "\n",
    "    # Imprime los resultados principales\n",
    "    print(data_frame.head()[[\"score\", \"file_name\"]])\n",
    "\n",
    "    # Obtiene la URL GCS del video más similar\n",
    "    url = data_frame.iloc[0][\"gcs_path\"]\n",
    "\n",
    "    # Muestra el video en el notebook\n",
    "    display_video_from_gcs(url)\n",
    "\n",
    "\n",
    "\n",
    "# --- Función para guardar embeddings en Google Cloud Storage como JSONL ---\n",
    "\n",
    "def guardar_embeddings_en_gcs(\n",
    "    project_id: str,\n",
    "    bucket_name: str,\n",
    "    blob_name: str,\n",
    "    ids: list[str],\n",
    "    embeddings: list[list[float]]\n",
    "):\n",
    "    \"\"\"\n",
    "    Convierte una lista de IDs y embeddings al formato JSONL y lo sube a GCS.\n",
    "\n",
    "    Args:\n",
    "        project_id (str): Tu proyecto de Google Cloud.\n",
    "        bucket_name (str): El nombre del bucket de destino.\n",
    "        blob_name (str): La ruta y nombre del archivo a crear en el bucket.\n",
    "        ids (list[str]): Lista de IDs únicos para cada embedding.\n",
    "        embeddings (list[list[float]]): La lista de vectores de embedding.\n",
    "    \"\"\"\n",
    "    print(f\"Conectando al bucket '{bucket_name}'...\")\n",
    "    storage_client = storage.Client(project=project_id)\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    print(f\"Escribiendo {len(ids)} embeddings en el archivo en memoria...\")\n",
    "    \n",
    "    # Usamos un context manager para escribir directamente al archivo en GCS\n",
    "    with blob.open(\"w\") as f:\n",
    "        for i, embedding in zip(ids, embeddings):\n",
    "            # Creamos el diccionario para la línea actual\n",
    "            data_point = {\"id\": i, \"embedding\": embedding}\n",
    "            # Lo convertimos a un string JSON y escribimos la línea en el archivo\n",
    "            f.write(json.dumps(data_point) + \"\\n\")\n",
    "\n",
    "    print(f\"¡Éxito! Archivo '{blob_name}' subido correctamente a 'gs://{bucket_name}/{blob_name}'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7296a3d3",
   "metadata": {},
   "source": [
    "# **Generamos los embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cdcf97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cargamos el modelo de embeddings multimodales ---\n",
    "mm_embendding_model = MultiModalEmbeddingModel.from_pretrained(\"multimodalembedding@001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b892321",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_video = \"gs://vboxioof/Videos/Videos Largos/azteca7-2025-05-23.mkv\" \n",
    "\n",
    "# Generamos el embedding del video\n",
    "video_embedding = get_video_embedding(ruta_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "224aa148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de embeddings generados: 30\n"
     ]
    }
   ],
   "source": [
    "# Vemos cuantos embeddings se generaron\n",
    "print(f\"Número de embeddings generados: {len(video_embedding)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280cf794",
   "metadata": {},
   "source": [
    "# **Carga a Vector Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9085a3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectando al bucket 'canalesparaprueba'...\n",
      "Escribiendo 8 embeddings en el archivo en memoria...\n",
      "¡Éxito! Archivo 'embeddings/video_embeddings_yago.json' subido correctamente a 'gs://canalesparaprueba/embeddings/video_embeddings_yago.json'.\n"
     ]
    }
   ],
   "source": [
    "# --- GENERACIÓN DE IDs ---\n",
    "ids_de_embeddings = [f\"VIDEOYAGO_segment_{i}\" for i in range(len(video_embedding))]\n",
    "\n",
    "\n",
    "if len(ids_de_embeddings) != len(video_embedding):\n",
    "        raise ValueError(\"La cantidad de IDs no coincide con la cantidad de embeddings.\")\n",
    "        \n",
    "guardar_embeddings_en_gcs(\n",
    "    project_id=PROJECT_ID,\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    blob_name=DESTINATION_BLOB_NAME,\n",
    "    ids=ids_de_embeddings,\n",
    "    embeddings=video_embedding\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbf4e48",
   "metadata": {},
   "source": [
    "# **Query a los embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dc059d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando embedding para el texto: 'GOVI'\n",
      "Conectando al Index Endpoint...\n",
      "Buscando los 8 videos más similares...\n",
      "\n",
      "--- RESULTADOS DE LA BÚSQUEDA ---\n",
      "\n",
      "Encontrado: [ID: 3] - [Distancia: 0.0364]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Mostrando segmento: <b>3</b> (segundos 12-16)</p>\n",
       "        <video width=\"640\" controls>\n",
       "            <source src=\"https://storage.googleapis.com/borrar_valerio/VIDEOYAGO.mp4#t=12,16\" type=\"video/mp4\">\n",
       "            Tu navegador no soporta la etiqueta de video.\n",
       "        </video>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encontrado: [ID: 2] - [Distancia: 0.0346]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Mostrando segmento: <b>2</b> (segundos 8-12)</p>\n",
       "        <video width=\"640\" controls>\n",
       "            <source src=\"https://storage.googleapis.com/borrar_valerio/VIDEOYAGO.mp4#t=8,12\" type=\"video/mp4\">\n",
       "            Tu navegador no soporta la etiqueta de video.\n",
       "        </video>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encontrado: [ID: 1] - [Distancia: 0.0316]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Mostrando segmento: <b>1</b> (segundos 4-8)</p>\n",
       "        <video width=\"640\" controls>\n",
       "            <source src=\"https://storage.googleapis.com/borrar_valerio/VIDEOYAGO.mp4#t=4,8\" type=\"video/mp4\">\n",
       "            Tu navegador no soporta la etiqueta de video.\n",
       "        </video>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encontrado: [ID: 4] - [Distancia: 0.0254]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Mostrando segmento: <b>4</b> (segundos 16-20)</p>\n",
       "        <video width=\"640\" controls>\n",
       "            <source src=\"https://storage.googleapis.com/borrar_valerio/VIDEOYAGO.mp4#t=16,20\" type=\"video/mp4\">\n",
       "            Tu navegador no soporta la etiqueta de video.\n",
       "        </video>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encontrado: [ID: 0] - [Distancia: 0.0243]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Mostrando segmento: <b>0</b> (segundos 0-4)</p>\n",
       "        <video width=\"640\" controls>\n",
       "            <source src=\"https://storage.googleapis.com/borrar_valerio/VIDEOYAGO.mp4#t=0,4\" type=\"video/mp4\">\n",
       "            Tu navegador no soporta la etiqueta de video.\n",
       "        </video>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# La ruta original de tu video. La necesitamos para poder mostrar el fragmento.\n",
    "GCS_VIDEO_URI = \"gs://borrar_valerio/VIDEOYAGO.mp4\"\n",
    "SEGMENT_INTERVAL_SEC = 4 # El intervalo en segundos que usaste para segmentar el video\n",
    "\n",
    "# --- INICIALIZACIÓN Y MODELOS ---\n",
    "# Asumo que vertexai.init() ya se ejecutó.\n",
    "# Creamos una instancia del modelo de embedding para usarlo en la función de texto.\n",
    "\n",
    "\n",
    "\n",
    "# --- EJECUCIÓN DE LA BÚSQUEDA ---\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # AQUÍ PONES TU CONSULTA EN LENGUAJE NATURAL\n",
    "    texto_de_busqueda = \"GOVI\"\n",
    "    # ------------------------------------------------------------------\n",
    "    \n",
    "    # 1. Obtenemos el embedding del texto de búsqueda\n",
    "    query_emb = get_text_embedding(texto_de_busqueda)\n",
    "    \n",
    "    # 2. Buscamos en Vector Search usando el embedding del texto\n",
    "    search_results = find_nearest_neighbors(query_emb)\n",
    "    \n",
    "    # 3. Mostramos los resultados\n",
    "    print(\"\\n--- RESULTADOS DE LA BÚSQUEDA ---\")\n",
    "    \n",
    "    if not search_results or not search_results[0]:\n",
    "        print(\"No se encontraron resultados.\")\n",
    "    else:\n",
    "        for neighbor in search_results[0]:\n",
    "            video_segment_id = neighbor.id\n",
    "            distancia = neighbor.distance\n",
    "            print(f\"\\nEncontrado: [ID: {video_segment_id}] - [Distancia: {distancia:.8f}]\")\n",
    "            \n",
    "            # Mostramos el fragmento de video correspondiente\n",
    "            display_video_segment(\n",
    "                video_gcs_uri=GCS_VIDEO_URI,\n",
    "                segment_id=video_segment_id,\n",
    "                interval=SEGMENT_INTERVAL_SEC\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
