{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ce26080",
   "metadata": {},
   "source": [
    "# **Importamos las dependencias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d508109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Para el proceso de datos y visualizaci√≥n ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from google.cloud import storage\n",
    "\n",
    "\n",
    "\n",
    "# --- Dependencias de Vertex AI ---\n",
    "import vertexai                                              # Importa el m√≥dulo principal de Vertex AI.\n",
    "from vertexai import init                                    # Inicializa Vertex AI con las credenciales y configuraciones necesarias.\n",
    "from vertexai.vision_models import MultiModalEmbeddingModel  # Importa el modelo de embeddings multimodales de Vertex AI para procesar im√°genes y videos.\n",
    "from vertexai.vision_models import Video                     # Clase para manejar archivos de video en Vertex AI.\n",
    "from vertexai.vision_models import VideoSegmentConfig        # Configuraci√≥n para segmentar videos al gener\n",
    "from google.cloud.aiplatform.matching_engine import MatchingEngineIndexEndpoint \n",
    "from vertexai.vision_models import Image\n",
    "\n",
    "# --- Dependencias para poder visualizar ---\n",
    "from IPython.display import Video as MVideo                  # Permite mostrar videos directamente en celdas de Jupyter Notebook.\n",
    "from IPython.display import HTML                             # Permite mostrar contenido HTML en celdas de Jupyter Notebook.\n",
    "from IPython.display import Image as ImageByte               # Permite mostrar im√°genes en el notebook (renombrado como ImageByte para evitar conflictos de nombres).\n",
    "from IPython.display import display                          # Funci√≥n general para mostrar objetos en el notebook.\n",
    "from sklearn.metrics.pairwise import cosine_similarity       # Funci√≥n para calcular la similitud coseno entre vectores, √∫til para comparar embeddings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fbd619",
   "metadata": {},
   "source": [
    "# **Configuraci√≥n del entorno de Vertex**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5872b28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cargamos el modelo de embeddings multimodales ---\n",
    "mm_embendding_model = MultiModalEmbeddingModel.from_pretrained(\"multimodalembedding@001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5917d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cargamos las credewntiales de Vertex AI ---\n",
    "\n",
    "PROJECT_ID = \"dauntless-drive-462416-q3\"\n",
    "LOCATION = \"us-central1\"\n",
    "\n",
    "\n",
    "# --- Inicializamos Vertex AI ---\n",
    "init(project = PROJECT_ID, location = LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a57b90a",
   "metadata": {},
   "source": [
    "# **Funciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08e114e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Funci√≥n para generar embeddings de videos ---\n",
    "\n",
    "def get_video_embedding(ruta_video: str) -> list: \n",
    "    \n",
    "    \"\"\"\n",
    "    Genera un embedding para un video dado.\n",
    "\n",
    "    Args:\n",
    "        ruta_video (str): Ruta al archivo de video.\n",
    "\n",
    "    Returns:\n",
    "        list: Embedding del video.\n",
    "    \"\"\"\n",
    "    # Cargamos el video desde la ruta proporcionada\n",
    "    video = Video.load_from_file(ruta_video)\n",
    "    \n",
    "    # Genera el embedding del video utilizando el modelo de embeddings multimodales\n",
    "    embedding = mm_embendding_model.get_embeddings(video = video, \n",
    "                                                   video_segment_config = VideoSegmentConfig(interval_sec=4) # Configura el segmento del video para generar embeddings cada 4 segundos.\n",
    "                                                  )\n",
    "    \n",
    "    return [video_emb.embedding for video_emb in embedding.video_embeddings]  # Retorna una lista de embeddings para cada segmento del video.\n",
    "\n",
    "\n",
    "# --- Funci√≥n para generar embeddings de texto ---\n",
    "\n",
    "def get_text_embedding(text: str) -> list:\n",
    "    \"\"\"Genera un embedding para un texto dado.\"\"\"\n",
    "    print(f\"Generando embedding para el texto: '{text}'\")\n",
    "    embeddings = mm_embendding_model.get_embeddings(\n",
    "        contextual_text=text,\n",
    "    )\n",
    "    return embeddings.text_embedding\n",
    "\n",
    "\n",
    "# --- Funci√≥n para generar embeddings de im√°genes ---\n",
    "\n",
    "def get_image_embedding(image_path: str) -> list:\n",
    "    \"\"\"\n",
    "    Genera embeddings para una imagen local o en GCS.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Ruta a la imagen (puede ser local o gs://)\n",
    "        \n",
    "    Returns:\n",
    "        list: Vector de embedding de la imagen\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"üì∑ Procesando imagen: {image_path}\")\n",
    "        \n",
    "        # Cargar la imagen (funciona con rutas locales y GCS)\n",
    "        image = Image.load_from_file(image_path)\n",
    "        \n",
    "        # Generar embedding\n",
    "        embeddings = mm_embendding_model.get_embeddings(image=image)\n",
    "        \n",
    "        print(\"‚úÖ Embedding generado exitosamente\")\n",
    "        return embeddings.image_embedding\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al generar embedding: {e}\")\n",
    "        return Non\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def find_nearest_neighbors(query_embedding: list, num_neighbors: int = 2):\n",
    "    \"\"\"Busca los N vecinos m√°s cercanos a un embedding de consulta.\"\"\"\n",
    "    print(\"Conectando al Index Endpoint...\")\n",
    "    index_endpoint = MatchingEngineIndexEndpoint(index_endpoint_name=INDEX_ENDPOINT_NAME)\n",
    "    \n",
    "    print(f\"Buscando los {num_neighbors} videos m√°s similares...\")\n",
    "    neighbors = index_endpoint.find_neighbors(\n",
    "        deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "        queries=[query_embedding],\n",
    "        num_neighbors=num_neighbors\n",
    "    )\n",
    "    return neighbors\n",
    "\n",
    "def display_video_segment(video_gcs_uri: str, segment_id: str, interval: int):\n",
    "    \"\"\"Muestra un reproductor de video HTML que apunta a un segmento espec√≠fico.\"\"\"\n",
    "    try:\n",
    "        # Extraemos el n√∫mero del segmento del ID. Ej: \"VIDEOYAGO_segment_5\" -> 5\n",
    "        segment_number = int(segment_id.split('_')[-1])\n",
    "        start_time = segment_number * interval\n",
    "        end_time = start_time + interval\n",
    "        \n",
    "        # Convertimos la URI de gs:// a una URL p√∫blica de https://\n",
    "        public_url = video_gcs_uri.replace(\"gs://\", \"https://storage.googleapis.com/\")\n",
    "        \n",
    "        # Creamos el c√≥digo HTML para el video, apuntando al tiempo de inicio\n",
    "        video_html = f\"\"\"\n",
    "        <p>Mostrando segmento: <b>{segment_id}</b> (segundos {start_time}-{end_time})</p>\n",
    "        <video width=\"640\" controls>\n",
    "            <source src=\"{public_url}#t={start_time},{end_time}\" type=\"video/mp4\">\n",
    "            Tu navegador no soporta la etiqueta de video.\n",
    "        </video>\n",
    "        \"\"\"\n",
    "        display(HTML(video_html))\n",
    "        \n",
    "    except (ValueError, IndexError) as e:\n",
    "        print(f\"No se pudo parsear el ID del segmento '{segment_id}'. Error: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Convierte una URI de Google Cloud Storage a una URL p√∫blica accesible por HTTP ---\n",
    "\n",
    "def get_public_url_from_gcs(gcs_uri: str) -> str:\n",
    "    \"\"\"\n",
    "    Convierte una URI de Google Cloud Storage (gs://bucket/archivo) a una URL p√∫blica HTTP.\n",
    "\n",
    "    Args:\n",
    "        gcs_uri (str): URI de Google Cloud Storage.\n",
    "\n",
    "    Returns:\n",
    "        str: URL p√∫blica accesible desde el navegador.\n",
    "    \"\"\"\n",
    "    return gcs_uri.replace(\"gs://\", \"https://storage.googleapis.com/\").replace(\n",
    "        \" \", \"%20\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# --- Muestra un video almacenado en Google Cloud Storage en el notebook ---\n",
    "\n",
    "def display_video_from_gcs(gcs_uri: str) -> None:\n",
    "    \"\"\"\n",
    "    Muestra un video almacenado en Google Cloud Storage directamente en el notebook.\n",
    "\n",
    "    Args:\n",
    "        gcs_uri (str): URI de Google Cloud Storage del video.\n",
    "    \"\"\"\n",
    "    public_url = get_public_url_from_gcs(gcs_uri)\n",
    "    display(\n",
    "        HTML(\n",
    "            f\"\"\"\n",
    "            <video width=\"480\" controls>\n",
    "                <source src=\"{public_url}\" type=\"video/mp4\">\n",
    "                Tu navegador no soporta la reproducci√≥n de video.\n",
    "            </video>\n",
    "            \"\"\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# --- Funci√≥n para imprimir videos similares basados en embeddings ---\n",
    "\n",
    "def print_similar_videos(query_emb: list[float], data_frame: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Calcula la similitud (producto punto) entre un embedding de consulta y los embeddings de videos almacenados en un DataFrame.\n",
    "    Muestra los videos m√°s similares y despliega el video m√°s relevante en el notebook.\n",
    "\n",
    "    Args:\n",
    "        query_emb (list[float]): Embedding de consulta (por ejemplo, generado a partir de un video o texto).\n",
    "        data_frame (pd.DataFrame): DataFrame que contiene al menos las columnas 'video_embeddings', 'file_name' y 'gcs_path'.\n",
    "\n",
    "    Funcionamiento:\n",
    "        - Calcula el producto punto entre el embedding de consulta y cada embedding de video en el DataFrame.\n",
    "        - A√±ade una columna 'score' con los resultados de similitud.\n",
    "        - Ordena el DataFrame por 'score' de mayor a menor.\n",
    "        - Imprime los nombres de los archivos y sus scores m√°s altos.\n",
    "        - Muestra el video m√°s similar directamente en el notebook.\n",
    "    \"\"\"\n",
    "    # Obtiene la columna de embeddings de video\n",
    "    video_embs = data_frame[\"video_embeddings\"]\n",
    "\n",
    "    # Calcula el producto punto entre cada embedding y el de consulta\n",
    "    scores = [np.dot(eval(video_emb), query_emb) for video_emb in video_embs]\n",
    "    data_frame[\"score\"] = scores\n",
    "\n",
    "    # Ordena por score descendente\n",
    "    data_frame = data_frame.sort_values(by=\"score\", ascending=False)\n",
    "\n",
    "    # Imprime los resultados principales\n",
    "    print(data_frame.head()[[\"score\", \"file_name\"]])\n",
    "\n",
    "    # Obtiene la URL GCS del video m√°s similar\n",
    "    url = data_frame.iloc[0][\"gcs_path\"]\n",
    "\n",
    "    # Muestra el video en el notebook\n",
    "    display_video_from_gcs(url)\n",
    "\n",
    "\n",
    "\n",
    "# --- Funci√≥n para guardar embeddings en Google Cloud Storage como JSONL ---\n",
    "\n",
    "def guardar_embeddings_en_gcs(\n",
    "    project_id: str,\n",
    "    bucket_name: str,\n",
    "    blob_name: str,\n",
    "    ids: list[str],\n",
    "    embeddings: list[list[float]]\n",
    "):\n",
    "    \"\"\"\n",
    "    Convierte una lista de IDs y embeddings al formato JSONL y lo sube a GCS.\n",
    "\n",
    "    Args:\n",
    "        project_id (str): Tu proyecto de Google Cloud.\n",
    "        bucket_name (str): El nombre del bucket de destino.\n",
    "        blob_name (str): La ruta y nombre del archivo a crear en el bucket.\n",
    "        ids (list[str]): Lista de IDs √∫nicos para cada embedding.\n",
    "        embeddings (list[list[float]]): La lista de vectores de embedding.\n",
    "    \"\"\"\n",
    "    print(f\"Conectando al bucket '{bucket_name}'...\")\n",
    "    storage_client = storage.Client(project=project_id)\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    print(f\"Escribiendo {len(ids)} embeddings en el archivo en memoria...\")\n",
    "    \n",
    "    # Usamos un context manager para escribir directamente al archivo en GCS\n",
    "    with blob.open(\"w\") as f:\n",
    "        for i, embedding in zip(ids, embeddings):\n",
    "            # Creamos el diccionario para la l√≠nea actual\n",
    "            data_point = {\"id\": i, \"embedding\": embedding}\n",
    "            # Lo convertimos a un string JSON y escribimos la l√≠nea en el archivo\n",
    "            f.write(json.dumps(data_point) + \"\\n\")\n",
    "\n",
    "    print(f\"¬°√âxito! Archivo '{blob_name}' subido correctamente a 'gs://{bucket_name}/{blob_name}'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7296a3d3",
   "metadata": {},
   "source": [
    "# **Generamos los embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b892321",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_video = \"gs://canalesparaprueba/VIDEOYAGO.mp4\" # Ruta al video\n",
    "\n",
    "# Generamos el embedding del video\n",
    "video_embedding = get_video_embedding(ruta_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "224aa148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(video_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280cf794",
   "metadata": {},
   "source": [
    "# **Carga a Vector Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9085a3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectando al bucket 'canalesparaprueba'...\n",
      "Escribiendo 8 embeddings en el archivo en memoria...\n",
      "¬°√âxito! Archivo 'embeddings/video_embeddings_yago.json' subido correctamente a 'gs://canalesparaprueba/embeddings/video_embeddings_yago.json'.\n"
     ]
    }
   ],
   "source": [
    "INDEX_ENDPOINT_NAME = \"projects/144706985230/locations/us-central1/indexEndpoints/7120122841151832064\"\n",
    "DEPLOYED_INDEX_ID = \"embeddings_video_yago_prue_1749587612895\"\n",
    "BUCKET_NAME = \"canalesparaprueba\" #  Aqu√≠ era otro bucket, me equivoqu√© xd\n",
    "DESTINATION_BLOB_NAME = \"embeddings/video_embeddings_yago.json\" \n",
    "\n",
    "\n",
    "# --- GENERACI√ìN DE IDs ---\n",
    "ids_de_embeddings = [f\"VIDEOYAGO_segment_{i}\" for i in range(len(video_embedding))]\n",
    "\n",
    "\n",
    "if len(ids_de_embeddings) != len(video_embedding):\n",
    "        raise ValueError(\"La cantidad de IDs no coincide con la cantidad de embeddings.\")\n",
    "        \n",
    "guardar_embeddings_en_gcs(\n",
    "    project_id=PROJECT_ID,\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    blob_name=DESTINATION_BLOB_NAME,\n",
    "    ids=ids_de_embeddings,\n",
    "    embeddings=video_embedding\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbf4e48",
   "metadata": {},
   "source": [
    "# **Query a los embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49dc059d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando embedding para el texto: 'Volt'\n",
      "Conectando al Index Endpoint...\n",
      "Buscando los 2 videos m√°s similares...\n",
      "\n",
      "--- RESULTADOS DE LA B√öSQUEDA ---\n",
      "\n",
      "Encontrado: [ID: 3] - [Distancia: 0.0579]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Mostrando segmento: <b>3</b> (segundos 12-16)</p>\n",
       "        <video width=\"640\" controls>\n",
       "            <source src=\"https://storage.googleapis.com/borrar_valerio/VIDEOYAGO.mp4#t=12,16\" type=\"video/mp4\">\n",
       "            Tu navegador no soporta la etiqueta de video.\n",
       "        </video>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encontrado: [ID: 1] - [Distancia: 0.0572]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Mostrando segmento: <b>1</b> (segundos 4-8)</p>\n",
       "        <video width=\"640\" controls>\n",
       "            <source src=\"https://storage.googleapis.com/borrar_valerio/VIDEOYAGO.mp4#t=4,8\" type=\"video/mp4\">\n",
       "            Tu navegador no soporta la etiqueta de video.\n",
       "        </video>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# La ruta original de tu video. La necesitamos para poder mostrar el fragmento.\n",
    "GCS_VIDEO_URI = \"gs://borrar_valerio/VIDEOYAGO.mp4\"\n",
    "SEGMENT_INTERVAL_SEC = 4 # El intervalo en segundos que usaste para segmentar el video\n",
    "\n",
    "# --- INICIALIZACI√ìN Y MODELOS ---\n",
    "# Asumo que vertexai.init() ya se ejecut√≥.\n",
    "# Creamos una instancia del modelo de embedding para usarlo en la funci√≥n de texto.\n",
    "\n",
    "\n",
    "\n",
    "# --- EJECUCI√ìN DE LA B√öSQUEDA ---\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # AQU√ç PONES TU CONSULTA EN LENGUAJE NATURAL\n",
    "    texto_de_busqueda = \"Volt\"\n",
    "    # ------------------------------------------------------------------\n",
    "    \n",
    "    # 1. Obtenemos el embedding del texto de b√∫squeda\n",
    "    query_emb = get_text_embedding(texto_de_busqueda)\n",
    "    \n",
    "    # 2. Buscamos en Vector Search usando el embedding del texto\n",
    "    search_results = find_nearest_neighbors(query_emb)\n",
    "    \n",
    "    # 3. Mostramos los resultados\n",
    "    print(\"\\n--- RESULTADOS DE LA B√öSQUEDA ---\")\n",
    "    \n",
    "    if not search_results or not search_results[0]:\n",
    "        print(\"No se encontraron resultados.\")\n",
    "    else:\n",
    "        for neighbor in search_results[0]:\n",
    "            video_segment_id = neighbor.id\n",
    "            distancia = neighbor.distance\n",
    "            print(f\"\\nEncontrado: [ID: {video_segment_id}] - [Distancia: {distancia:.4f}]\")\n",
    "            \n",
    "            # Mostramos el fragmento de video correspondiente\n",
    "            display_video_segment(\n",
    "                video_gcs_uri=GCS_VIDEO_URI,\n",
    "                segment_id=video_segment_id,\n",
    "                interval=SEGMENT_INTERVAL_SEC\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6bd4d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì∑ Procesando imagen: gs://imagenes_logos/mcdonalds.png\n",
      "‚úÖ Embedding generado exitosamente\n",
      "üî¢ Dimensi√≥n del embedding: 1408\n",
      "\n",
      "üîç Buscando videos similares...\n",
      "Conectando al Index Endpoint...\n",
      "Buscando los 3 videos m√°s similares...\n",
      "\n",
      "üé¨ Segmentos de video encontrados:\n",
      "\n",
      "ID: 3 | Similitud: 0.4739\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Mostrando segmento: <b>3</b> (segundos 12-16)</p>\n",
       "        <video width=\"640\" controls>\n",
       "            <source src=\"https://storage.googleapis.com/borrar_valerio/VIDEOYAGO.mp4#t=12,16\" type=\"video/mp4\">\n",
       "            Tu navegador no soporta la etiqueta de video.\n",
       "        </video>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ID: 0 | Similitud: 0.4589\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Mostrando segmento: <b>0</b> (segundos 0-4)</p>\n",
       "        <video width=\"640\" controls>\n",
       "            <source src=\"https://storage.googleapis.com/borrar_valerio/VIDEOYAGO.mp4#t=0,4\" type=\"video/mp4\">\n",
       "            Tu navegador no soporta la etiqueta de video.\n",
       "        </video>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ID: 4 | Similitud: 0.4092\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Mostrando segmento: <b>4</b> (segundos 16-20)</p>\n",
       "        <video width=\"640\" controls>\n",
       "            <source src=\"https://storage.googleapis.com/borrar_valerio/VIDEOYAGO.mp4#t=16,20\" type=\"video/mp4\">\n",
       "            Tu navegador no soporta la etiqueta de video.\n",
       "        </video>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Configuraci√≥n\n",
    "    IMAGE_PATH = \"gs://imagenes_logos/mcdonalds.png\"\n",
    "    \n",
    "    # 1. Generar embedding\n",
    "    image_embedding = get_image_embedding(IMAGE_PATH)\n",
    "    \n",
    "    # 2. Verificar resultados\n",
    "    if image_embedding:\n",
    "        print(f\"üî¢ Dimensi√≥n del embedding: {len(image_embedding)}\")\n",
    "        \n",
    "        \n",
    "        # 3. Opcional: Buscar videos similares\n",
    "        print(\"\\nüîç Buscando videos similares...\")\n",
    "        search_results = find_nearest_neighbors(image_embedding, num_neighbors=3)\n",
    "        \n",
    "        # Mostrar resultados\n",
    "        if search_results and search_results[0]:\n",
    "            print(f\"\\nüé¨ Segmentos de video encontrados:\")\n",
    "            for neighbor in search_results[0]:\n",
    "                video_segment_id = neighbor.id\n",
    "                distancia = neighbor.distance\n",
    "                print(f\"\\nID: {video_segment_id } | Similitud: {distancia:.4F}\")\n",
    "                \n",
    "                display_video_segment(\n",
    "                    video_gcs_uri=GCS_VIDEO_URI,\n",
    "                    segment_id=neighbor.id,\n",
    "                    interval=SEGMENT_INTERVAL_SEC\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
