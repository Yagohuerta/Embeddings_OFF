{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f30e6a11",
   "metadata": {},
   "source": [
    "# **Importamos las dependencias**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d938dfe",
   "metadata": {},
   "source": [
    "Estoy importando todas las dependencias de mis cuadernos, despues las depuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "738a5349",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'vertexai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# --- Importamos Vertex AI ---\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mvertexai\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# --- Importaciones para Visualizaci√≥n y Formato de Texto ---\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Se utiliza para mostrar contenido enriquecido, como texto con formato Markdown,\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# directamente en entornos como Jupyter Notebooks o IPython.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Markdown, display\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'vertexai'"
     ]
    }
   ],
   "source": [
    "# --- Importaciones para Manejo de Archivos y Directorios ---\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "# --- Importamos Vertex AI ---\n",
    "import vertexai\n",
    "\n",
    "\n",
    "# --- Importaciones para Visualizaci√≥n y Formato de Texto ---\n",
    "\n",
    "# Se utiliza para mostrar contenido enriquecido, como texto con formato Markdown,\n",
    "# directamente en entornos como Jupyter Notebooks o IPython.\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Importa la clase `Markdown` de la biblioteca `rich`, que sirve para renderizar\n",
    "# Markdown con formato avanzado en la terminal. Se le da un alias `RichMarkdown`\n",
    "# para evitar conflictos de nombre con la importaci√≥n anterior.\n",
    "from rich.markdown import Markdown as RichMarkdown\n",
    "\n",
    "\n",
    "# --- Importaciones para el Modelo Generativo de Vertex AI ---\n",
    "\n",
    "# Importa las clases necesarias del SDK de Vertex AI para interactuar con los modelos generativos.\n",
    "# - GenerationConfig: Para configurar los par√°metros de la respuesta (ej. temperatura, top_p).\n",
    "# - GenerativeModel: La clase principal para cargar y usar un modelo generativo como Gemini.\n",
    "# - Image: Para manejar y enviar im√°genes como parte de la entrada al modelo (enfoque multimodal).\n",
    "from vertexai.generative_models import GenerationConfig, GenerativeModel, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41f23316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81a731d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "# --- Para el proceso de datos y visualizaci√≥n ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "\n",
    "# --- Para manejar las variables de entorno ---\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# --- Desactiva las advertencias de asignaciones encadenadas en pandas para evitar mensajes de warning al modificar DataFrames.\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "\n",
    "# --- Dependencias de Vertex AI ---\n",
    "import vertexai                                              # Importa el m√≥dulo principal de Vertex AI.\n",
    "from vertexai import init                                    # Inicializa Vertex AI con las credenciales y configuraciones necesarias.\n",
    "from vertexai.vision_models import Image as VMImage          # Importa la clase Image de Vertex AI para manejar im√°genes.\n",
    "from vertexai.vision_models import MultiModalEmbeddingModel  # Importa el modelo de embeddings multimodales de Vertex AI para procesar im√°genes y videos.\n",
    "from vertexai.vision_models import Video                     # Clase para manejar archivos de video en Vertex AI.\n",
    "from vertexai.vision_models import VideoSegmentConfig        # Configuraci√≥n para segmentar videos\n",
    "from vertexai.generative_models import GenerativeModel       # Importa la clase para modelos generativos, como Gemini.\n",
    "from vertexai.generative_models import Part                  # Importa la clase Part para manejar partes de un mensaje, como texto o im√°genes.\n",
    "\n",
    "\n",
    "# --- Para conectarse y consultar un endpoint de b√∫squeda vectorial (Vector Search) en Vertex AI. \n",
    "from google.cloud.aiplatform.matching_engine import MatchingEngineIndexEndpoint \n",
    "\n",
    "# --- Para acceder a los buckets de Google Cloud Storage y manejar archivos.\n",
    "from google.cloud import storage\n",
    "\n",
    "\n",
    "# --- Dependencias para poder visualizar ---\n",
    "from IPython.display import Video as MVideo                  # Permite mostrar videos directamente en celdas de Jupyter Notebook.\n",
    "from IPython.display import HTML                             # Permite mostrar contenido HTML en celdas de Jupyter Notebook.\n",
    "from IPython.display import Image as ImageByte               # Permite mostrar im√°genes en el notebook (renombrado como ImageByte para evitar conflictos de nombres).\n",
    "from IPython.display import display                          # Funci√≥n general para mostrar objetos en el notebook.\n",
    "from sklearn.metrics.pairwise import cosine_similarity       # Funci√≥n para calcular la similitud coseno entre vectores, √∫til para comparar embeddings.\n",
    "# --- Para el proceso de datos y visualizaci√≥n ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from google.cloud import storage\n",
    "\n",
    "\n",
    "\n",
    "# --- Dependencias de Vertex AI ---\n",
    "import vertexai                                              # Importa el m√≥dulo principal de Vertex AI.\n",
    "from vertexai import init                                    # Inicializa Vertex AI con las credenciales y configuraciones necesarias.\n",
    "from vertexai.vision_models import MultiModalEmbeddingModel  # Importa el modelo de embeddings multimodales de Vertex AI para procesar im√°genes y videos.\n",
    "from vertexai.vision_models import Video                     # Clase para manejar archivos de video en Vertex AI.\n",
    "from vertexai.vision_models import VideoSegmentConfig        # Configuraci√≥n para segmentar videos al gener\n",
    "from google.cloud.aiplatform.matching_engine import MatchingEngineIndexEndpoint \n",
    "from vertexai.vision_models import Image\n",
    "\n",
    "# --- Dependencias para poder visualizar ---\n",
    "from IPython.display import Video as MVideo                  # Permite mostrar videos directamente en celdas de Jupyter Notebook.\n",
    "from IPython.display import HTML                             # Permite mostrar contenido HTML en celdas de Jupyter Notebook.\n",
    "from IPython.display import Image as ImageByte               # Permite mostrar im√°genes en el notebook (renombrado como ImageByte para evitar conflictos de nombres).\n",
    "from IPython.display import display                          # Funci√≥n general para mostrar objetos en el notebook.\n",
    "from sklearn.metrics.pairwise import cosine_similarity   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628156ac",
   "metadata": {},
   "source": [
    "# **Configuraci√≥n de credenciales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "403e2df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proyecto: None, Ubicaci√≥n: None, √çndice: None, Endpoint: None, Bucket: None, Ruta de Videos: None\n"
     ]
    }
   ],
   "source": [
    "# --- Carga las Variables de Entorno ---\n",
    "load_dotenv()\n",
    "\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\")                        # ID del proyecto de Google Cloud\n",
    "LOCATION = os.getenv(\"LOCATION\")                            # Regi√≥n donde se encuentran los recursos de Vertex AI\n",
    "INDEX_ID = os.getenv(\"INDEX_ID\")                            # ID del √≠ndice de b√∫squeda vectorial en Vertex AI\n",
    "ENDPOINT_ID = os.getenv(\"ENDPOINT_ID\")                      # ID del endpoint de b√∫squeda vectorial en Vertex AI\n",
    "BUCKET_NAME = os.getenv(\"BUCKET_NAME\")                      # Nombre del bucket de Google Cloud Storage donde se almacenan los videos\n",
    "VIDEO_FOLDER_PATH = os.getenv(\"VIDEO_FOLDER_PATH\")          # Ruta del folder dentro del bucket donde se encuentran los videos\n",
    "\n",
    "# Verificamos que las variebles de entorno esten bien\n",
    "print(f\"Proyecto: {PROJECT_ID}, Ubicaci√≥n: {LOCATION}, √çndice: {INDEX_ID}, Endpoint: {ENDPOINT_ID}, Bucket: {BUCKET_NAME}, Ruta de Videos: {VIDEO_FOLDER_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6171fa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID=\"constant-setup-463820-p6\"\n",
    "LOCATION='us-central1'\n",
    "INDEX_ID = \"projects/640283206292/locations/us-central1/indexEndpoints/1468492336894836736\"\n",
    "ENDPOINT_ID = \"mexicocostarica_1750850443317\"\n",
    "VIDEO_FOLDER_PATH = 'Videos/Videos_Segmentados'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bb909a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciamos Vertex AI con el proyecto y la ubicaci√≥n especificados.\n",
    "init(project = PROJECT_ID, location = LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f569329e",
   "metadata": {},
   "source": [
    "# **Configuraci√≥n de Vertex AI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0d06bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inicializaci√≥n del LLM ---\n",
    "model = GenerativeModel('gemini-2.5-flash-lite-preview-06-17')\n",
    "embedding_model = MultiModalEmbeddingModel.from_pretrained(\"multimodalembedding@001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15024b8f",
   "metadata": {},
   "source": [
    "# **Funciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4627f08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://vboxiooof/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f03d43b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform_v1\n",
    "from vertexai.vision_models import MultiModalEmbeddingModel\n",
    "import re\n",
    "\n",
    "# Configuraci√≥n con tus valores exactos\n",
    "API_ENDPOINT = \"1584477394.us-central1-640283206292.vdb.vertexai.goog\"\n",
    "INDEX_ENDPOINT = \"projects/640283206292/locations/us-central1/indexEndpoints/1468492336894836736\"\n",
    "DEPLOYED_INDEX_ID = \"mexicocostarica_1750850443317\"\n",
    "BUCKET_NAME = \"vboxiooof\"\n",
    "VIDEO_FOLDER_PATH = \"Videos/Videos_Segmentados\"\n",
    "\n",
    "# Inicializaci√≥n del modelo de embeddings (hazlo solo una vez)\n",
    "embedding_model = MultiModalEmbeddingModel.from_pretrained(\"multimodalembedding@001\")\n",
    "\n",
    "def buscar_videos_similares(\n",
    "    texto_pregunta: str,\n",
    "    num_resultados: int = 5\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Implementaci√≥n basada en la documentaci√≥n oficial de Vertex AI\n",
    "    \n",
    "    Args:\n",
    "        texto_pregunta: Texto para convertir en embedding y buscar similitudes\n",
    "        num_resultados: N√∫mero de videos similares a retornar\n",
    "        \n",
    "    Returns:\n",
    "        Lista de URIs de videos encontrados (ej. [\"gs://vboxiooof/Videos/video_001.mkv\"])\n",
    "    \"\"\"\n",
    "    print(\"üîç Paso 1/3: Generando embedding del texto...\")\n",
    "    try:\n",
    "        # Generar embedding del texto\n",
    "        embedding = embedding_model.get_embeddings(\n",
    "            contextual_text=texto_pregunta\n",
    "        ).text_embedding\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al generar embedding: {e}\")\n",
    "        return []\n",
    "\n",
    "    print(\"üîó Paso 2/3: Configurando cliente de Vector Search...\")\n",
    "    try:\n",
    "        # Configurar cliente como indica la documentaci√≥n\n",
    "        client_options = {\"api_endpoint\": API_ENDPOINT}\n",
    "        client = aiplatform_v1.MatchServiceClient(client_options=client_options)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al configurar cliente: {e}\")\n",
    "        return []\n",
    "\n",
    "    print(f\"üì° Paso 3/3: Buscando {num_resultados} videos similares...\")\n",
    "    try:\n",
    "        # Construir solicitud como en la documentaci√≥n\n",
    "        datapoint = aiplatform_v1.IndexDatapoint(\n",
    "            datapoint_id=\"query_embedding\",\n",
    "            feature_vector=embedding\n",
    "        )\n",
    "\n",
    "        query = aiplatform_v1.FindNeighborsRequest.Query(\n",
    "            datapoint=datapoint,\n",
    "            neighbor_count=num_resultados\n",
    "        )\n",
    "\n",
    "        request = aiplatform_v1.FindNeighborsRequest(\n",
    "            index_endpoint=INDEX_ENDPOINT,\n",
    "            deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "            queries=[query],\n",
    "            return_full_datapoint=True  # Necesario para obtener los IDs\n",
    "        )\n",
    "\n",
    "        # Ejecutar la solicitud\n",
    "        response = client.find_neighbors(request)\n",
    "\n",
    "        # Procesar resultados\n",
    "        uris = []\n",
    "        for neighbor in response.nearest_neighbors[0].neighbors:\n",
    "            video_id = neighbor.datapoint.datapoint_id\n",
    "            try:\n",
    "                if '_' in video_id:\n",
    "                    prefix, num = video_id.rsplit('_', 1)\n",
    "                    uri = f\"/{prefix}_{num.zfill(3)}\"\n",
    "                    uris.append(uri)\n",
    "                    print(f\"‚úÖ Embedding encontrado: {uri}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error procesando {video_id}: {e}\")\n",
    "\n",
    "        return uris\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en la b√∫squeda vectorial: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "ce5651a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#version modificada para manejar correctamente los segmentos de video\n",
    "\n",
    "\n",
    "\n",
    "def analizar_fragmentos_con_gemini(\n",
    "    pregunta_original: str,\n",
    "    uris_de_videos: list[str]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Versi√≥n final que maneja correctamente el formato de 3 d√≠gitos en los segmentos\n",
    "    \n",
    "    Args:\n",
    "        pregunta_original: Pregunta del usuario\n",
    "        uris_de_videos: Lista de URIs encontradas por Vector Search\n",
    "        \n",
    "    Returns:\n",
    "        Respuesta generada por Gemini basada en los videos\n",
    "    \"\"\"\n",
    "    if not uris_de_videos:\n",
    "        return \"No se encontraron videos relevantes para analizar.\"\n",
    "\n",
    "    print(f\"\\nüì¶ Procesando {len(uris_de_videos)} URIs de video...\")\n",
    "    \n",
    "    # Procesamos las URIs para obtener los segmentos reales (3 d√≠gitos)\n",
    "    videos_reales = set()  # Usamos un set para evitar duplicados\n",
    "    \n",
    "\n",
    "    #Funcion para obtener el numero real del video\n",
    "    for uri in uris_de_videos:\n",
    "        try:\n",
    "            # Extraemos el n√∫mero de segmento del URI\n",
    "            nombre_archivo = uri.split('/')[-1].replace('.mkv', '')\n",
    "            base, num_str = nombre_archivo.rsplit('_', 1)\n",
    "            num = int(num_str)\n",
    "            \n",
    "            # Calculamos el segmento real de video (cada video tiene 4 embeddings)\n",
    "            segmento_real = num // 4\n",
    "            \n",
    "            # Formateamos a 3 d√≠gitos (041 en lugar de 0041)\n",
    "            uri_real = f\"gs://{BUCKET_NAME}/{VIDEO_FOLDER_PATH}/{base}_{segmento_real:03d}.mkv\"\n",
    "            \n",
    "            videos_reales.add(uri_real)\n",
    "            print(f\"üîç Mapeado: {uri} -> {uri_real}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error procesando {uri}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not videos_reales:\n",
    "        return \"No se pudieron mapear los segmentos a videos reales.\"\n",
    "\n",
    "    print(f\"\\nüé¨ Videos reales a analizar ({len(videos_reales)}):\")\n",
    "    for video in videos_reales:\n",
    "        print(f\" - {video}\")\n",
    "\n",
    "    # Convertimos las URIs reales a partes para Gemini\n",
    "    try:\n",
    "        video_parts = [Part.from_uri(uri, mime_type=\"video/mkv\") for uri in videos_reales]\n",
    "        \n",
    "        prompt = [\n",
    "            \"Eres un experto analista de video. Analiza ESTOS VIDEOS EXACTOS:\",\n",
    "            *video_parts,\n",
    "            \"\\nPREGUNTA DEL USUARIO:\",\n",
    "            pregunta_original,\n",
    "            \"\\nINSTRUCCIONES:\",\n",
    "            \"1. Responde basado SOLO en los videos proporcionados\",\n",
    "            \"2. S√© preciso y conciso\",\n",
    "            \"3. Incluye referencias temporales cuando sea relevante\",\n",
    "            \"4. Si no hay informaci√≥n, di 'No encontrado en los videos'\"\n",
    "        ]\n",
    "        \n",
    "        print(\"\\nüß† Enviando a Gemini para an√°lisis...\")\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error al analizar videos: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1924493a",
   "metadata": {},
   "source": [
    "# **Pruebas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "9dcfe01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INICIANDO PROCESO DE RAG MULTIMODAL ---\n",
      "üîç Paso 1/3: Generando embedding del texto...\n",
      "üîó Paso 2/3: Configurando cliente de Vector Search...\n",
      "üì° Paso 3/3: Buscando 5 videos similares...\n",
      "‚ùå Error en la b√∫squeda vectorial: 503 failed to connect to all addresses; last error: UNAVAILABLE: ipv4:34.36.170.103:443: Failed to connect to remote host: Timeout occurred: FD shutdown\n",
      "\n",
      "--- RESPUESTA FINAL DE GEMINI ---\n",
      "No se encontraron videos relevantes para analizar.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# --- 4. EJECUCI√ìN DEL FLUJO COMPLETO (Sin cambios) ---\n",
    "# --------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    pregunta_del_usuario = \"Caliente.mx en pantalla , anuncio de caliente, caliente palabra\"\n",
    "    print(\"--- INICIANDO PROCESO DE RAG MULTIMODAL ---\")\n",
    "    uris_relevantes = buscar_videos_similares(pregunta_del_usuario)\n",
    "    respuesta_final = analizar_fragmentos_con_gemini(pregunta_del_usuario, uris_relevantes)\n",
    "    print(\"\\n--- RESPUESTA FINAL DE GEMINI ---\")\n",
    "    print(respuesta_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "33442bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ Procesando 1 URIs de video...\n",
      "üîç Mapeado: gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_041.mkv -> gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_010.mkv\n",
      "\n",
      "üé¨ Videos reales a analizar (1):\n",
      " - gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_010.mkv\n",
      "\n",
      "üß† Enviando a Gemini para an√°lisis...\n"
     ]
    }
   ],
   "source": [
    "# Prueba m√≠nima con un video conocido\n",
    "test_uri = \"gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_041.mkv\"\n",
    "test_response = analizar_fragmentos_con_gemini(\"Describe este video\", [test_uri])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2afcdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRUEBAS PARA DETERMINAR UMBRAL\n",
    "\n",
    "\n",
    "\n",
    "from google.cloud import aiplatform_v1\n",
    "from vertexai.vision_models import MultiModalEmbeddingModel\n",
    "import re\n",
    "\n",
    "# Configuraci√≥n con tus valores exactos\n",
    "API_ENDPOINT = \"1584477394.us-central1-640283206292.vdb.vertexai.goog\"\n",
    "INDEX_ENDPOINT = \"projects/640283206292/locations/us-central1/indexEndpoints/1468492336894836736\"\n",
    "DEPLOYED_INDEX_ID = \"mexicocostarica_1750850443317\"\n",
    "BUCKET_NAME = \"vboxiooof\"\n",
    "VIDEO_FOLDER_PATH = \"Videos/Videos_Segmentados\"\n",
    "\n",
    "def buscar_videos_similares1(\n",
    "    texto_pregunta: str,\n",
    "    umbral_similaridad: float = 0.9,\n",
    "    num_resultados_max: int = 100\n",
    ") -> tuple[int, list[str]]:\n",
    "    \"\"\"\n",
    "    Versi√≥n modificada que busca todos los resultados que superen un umbral de similaridad\n",
    "    \n",
    "    Args:\n",
    "        texto_pregunta: Texto para convertir en embedding y buscar similitudes\n",
    "        umbral_similaridad: Umbral de similaridad (0.0 a 1.0) - 0.7 = 70%\n",
    "        num_resultados_max: M√°ximo n√∫mero de resultados a considerar\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (cantidad_resultados, lista_de_uris) donde:\n",
    "            - cantidad_resultados: N√∫mero total de videos que superaron el umbral\n",
    "            - lista_de_uris: Lista de URIs de videos encontrados\n",
    "    \"\"\"\n",
    "    print(\"üîç Paso 1/3: Generando embedding del texto...\")\n",
    "    try:\n",
    "        # Generar embedding del texto\n",
    "        embedding = embedding_model.get_embeddings(\n",
    "            contextual_text=texto_pregunta\n",
    "        ).text_embedding\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al generar embedding: {e}\")\n",
    "        return (0, [])\n",
    "\n",
    "    print(\"üîó Paso 2/3: Configurando cliente de Vector Search...\")\n",
    "    try:\n",
    "        client = aiplatform_v1.MatchServiceClient(\n",
    "            client_options={\"api_endpoint\": API_ENDPOINT}\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al configurar cliente: {e}\")\n",
    "        return (0, [])\n",
    "\n",
    "    print(f\"üì° Paso 3/3: Buscando videos con similaridad > {umbral_similaridad*100}%...\")\n",
    "    try:\n",
    "        # Configuramos para obtener muchos resultados y luego filtrar\n",
    "        datapoint = aiplatform_v1.IndexDatapoint(\n",
    "            datapoint_id=\"query_embedding\",\n",
    "            feature_vector=embedding\n",
    "        )\n",
    "\n",
    "        query = aiplatform_v1.FindNeighborsRequest.Query(\n",
    "            datapoint=datapoint,\n",
    "            neighbor_count=num_resultados_max  # Obtenemos el m√°ximo posible\n",
    "        )\n",
    "\n",
    "        request = aiplatform_v1.FindNeighborsRequest(\n",
    "            index_endpoint=INDEX_ENDPOINT,\n",
    "            deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "            queries=[query],\n",
    "            return_full_datapoint=True\n",
    "        )\n",
    "\n",
    "        # Ejecutar la solicitud\n",
    "        response = client.find_neighbors(request)\n",
    "\n",
    "        # Procesar resultados aplicando el umbral\n",
    "        resultados_validos = 0\n",
    "        uris = []\n",
    "        \n",
    "        for neighbor in response.nearest_neighbors[0].neighbors:\n",
    "            # Verificar similaridad (distance es 1 - similaridad)\n",
    "            similaridad = 1 - neighbor.distance\n",
    "            \n",
    "            if similaridad >= umbral_similaridad:\n",
    "                resultados_validos += 1\n",
    "                video_id = neighbor.datapoint.datapoint_id\n",
    "                try:\n",
    "                    if '_' in video_id:\n",
    "                        prefix, num = video_id.rsplit('_', 1)\n",
    "                        uri = f\"gs://{BUCKET_NAME}/{VIDEO_FOLDER_PATH}/{prefix}_{num.zfill(3)}.mkv\"\n",
    "                        uris.append(uri)\n",
    "                        print(f\"‚úÖ Video encontrado (similaridad: {similaridad:.2f}): {uri}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Error procesando {video_id}: {e}\")\n",
    "\n",
    "        print(f\"\\nüéØ Total de videos que superan el umbral: {resultados_validos}\")\n",
    "        return (resultados_validos, uris)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en la b√∫squeda vectorial: {e}\")\n",
    "        return (0, [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f7b73717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Paso 1/3: Generando embedding del texto...\n",
      "üîó Paso 2/3: Configurando cliente de Vector Search...\n",
      "üì° Paso 3/3: Buscando videos con similaridad > 90.0%...\n",
      "‚úÖ Video encontrado (similaridad: 0.90): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_1004.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.90): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_033.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.90): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_164.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.90): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_923.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.90): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_026.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.90): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_999.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.90): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_490.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.90): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_017.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.90): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_937.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.90): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_1088.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.90): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_013.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.90): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_1075.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.90): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_1089.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.90): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_992.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.90): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_1081.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.90): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_997.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_1497.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_1083.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_976.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_1059.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_489.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_1033.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_316.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_981.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_902.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_945.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_425.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_991.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_936.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_986.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_154.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_203.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_1384.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_908.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_929.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_988.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_015.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_201.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_973.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_978.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_046.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_1061.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_020.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_996.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_1035.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_1006.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_778.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_1618.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_1000.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_932.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_1007.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_427.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_1385.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.91): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_465.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.92): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_048.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.92): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_151.mkv\n",
      "‚úÖ Video encontrado (similaridad: 0.92): gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_1773.mkv\n",
      "\n",
      "üéØ Total de videos que superan el umbral: 57\n",
      "\n",
      "Total de videos relevantes: 57\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo 1: Obtener solo el conteo\n",
    "cantidad, _ = buscar_videos_similares1(\"Muestrame la marca Caliente\")\n",
    "print(f\"\\nTotal de videos relevantes: {cantidad}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4145cb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_videos_similares2(\n",
    "    texto_pregunta: str,\n",
    "    umbral_similaridad: float = 0.91,\n",
    "    num_resultados_max: int = 100\n",
    ") -> tuple[int, list[str]]:\n",
    "    \"\"\"\n",
    "    Versi√≥n final que aplica umbral de similaridad y divide segmentos entre 4\n",
    "    \n",
    "    Args:\n",
    "        texto_pregunta: Texto para buscar videos similares\n",
    "        umbral_similaridad: M√≠nima similaridad aceptada (0.7 = 70%)\n",
    "        num_resultados_max: M√°ximo de resultados a considerar para filtrar\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (total_resultados, lista_uris)\n",
    "            - total_resultados: Cantidad de videos que superaron el umbral\n",
    "            - lista_uris: URIs de videos reales (segmentos divididos entre 4)\n",
    "    \"\"\"\n",
    "    print(\"üîç Paso 1/3: Generando embedding del texto...\")\n",
    "    try:\n",
    "        embedding = embedding_model.get_embeddings(\n",
    "            contextual_text=texto_pregunta\n",
    "        ).text_embedding\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en embedding: {e}\")\n",
    "        return (0, [])\n",
    "\n",
    "    print(\"üîó Paso 2/3: Configurando cliente...\")\n",
    "    try:\n",
    "        client = aiplatform_v1.MatchServiceClient(\n",
    "            client_options={\"api_endpoint\": API_ENDPOINT}\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en cliente: {e}\")\n",
    "        return (0, [])\n",
    "\n",
    "    print(f\"üì° Paso 3/3: Buscando videos (similaridad > {umbral_similaridad*100}%)...\")\n",
    "    try:\n",
    "        # Configuraci√≥n de b√∫squeda\n",
    "        request = aiplatform_v1.FindNeighborsRequest(\n",
    "            index_endpoint=INDEX_ENDPOINT,\n",
    "            deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "            queries=[aiplatform_v1.FindNeighborsRequest.Query(\n",
    "                datapoint=aiplatform_v1.IndexDatapoint(feature_vector=embedding),\n",
    "                neighbor_count=num_resultados_max\n",
    "            )],\n",
    "            return_full_datapoint=True\n",
    "        )\n",
    "\n",
    "        response = client.find_neighbors(request)\n",
    "        resultados_validos = 0\n",
    "        uris_reales = set()  # Usamos set para evitar duplicados\n",
    "\n",
    "        for neighbor in response.nearest_neighbors[0].neighbors:\n",
    "            similaridad = 1 - neighbor.distance\n",
    "            \n",
    "            if similaridad >= umbral_similaridad:\n",
    "                resultados_validos += 1\n",
    "                video_id = neighbor.datapoint.datapoint_id\n",
    "                \n",
    "                try:\n",
    "                    if '_' in video_id:\n",
    "                        # Dividimos el n√∫mero de segmento entre 4\n",
    "                        prefix, num_str = video_id.rsplit('_', 1)\n",
    "                        num_segmento = int(num_str)\n",
    "                        num_video_real = num_segmento // 4\n",
    "                        \n",
    "                        # Formateamos a 3 d√≠gitos (041)\n",
    "                        uri_real = f\"gs://{BUCKET_NAME}/{VIDEO_FOLDER_PATH}/{prefix}_{num_video_real:03d}.mkv\"\n",
    "                        uris_reales.add(uri_real)\n",
    "                        \n",
    "                        print(f\"‚úÖ Match (sim: {similaridad:.2f}): {video_id} ‚Üí {uri_real}\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Error procesando {video_id}: {e}\")\n",
    "\n",
    "        print(f\"\\nüéØ Total sobre umbral: {resultados_validos}\")\n",
    "        print(f\"üé¨ Videos √∫nicos encontrados: {len(uris_reales)}\")\n",
    "        \n",
    "        return (resultados_validos, list(uris_reales))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en b√∫squeda: {e}\")\n",
    "        return (0, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "9fce6116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform_v1\n",
    "from vertexai.vision_models import MultiModalEmbeddingModel\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "import re\n",
    "\n",
    "def buscar_videos_similares4(\n",
    "    texto_de_la_pregunta: str,\n",
    "    cantidad_de_resultados: int = 5\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Versi√≥n corregida con la conexi√≥n adecuada a Vertex AI Vector Search\n",
    "    \n",
    "    Args:\n",
    "        texto_de_la_pregunta: Texto para convertir en embedding y buscar similitudes\n",
    "        cantidad_de_resultados: N√∫mero de videos similares a retornar\n",
    "        \n",
    "    Returns:\n",
    "        Lista de URIs de videos encontrados (ej. [\"gs://vboxiooof/Videos/Videos_Segmentados/mexicosta_segment_001.mkv\"])\n",
    "    \"\"\"\n",
    "    print(f\"PASO 2.1: Creando embedding para la pregunta: '{texto_de_la_pregunta}'\")\n",
    "    try:\n",
    "        # Generaci√≥n del embedding (se mantiene igual)\n",
    "        vector_de_la_pregunta = embedding_model.get_embeddings(\n",
    "            contextual_text=texto_de_la_pregunta\n",
    "        ).text_embedding\n",
    "    except Exception as e:\n",
    "        print(f\"Error al generar embedding de texto: {e}\")\n",
    "        return []\n",
    "\n",
    "    print(\"PASO 2.2: Configurando cliente de Vector Search...\")\n",
    "    try:\n",
    "        # CONEXI√ìN CORREGIDA (seg√∫n documentaci√≥n oficial)\n",
    "        client_options = {\"api_endpoint\": API_ENDPOINT}\n",
    "        client = aiplatform_v1.MatchServiceClient(client_options=client_options)\n",
    "    except Exception as e:\n",
    "        print(f\"Error al configurar cliente Vector Search: {e}\")\n",
    "        return []\n",
    "\n",
    "    print(f\"PASO 2.3: Buscando {cantidad_de_resultados} videos similares...\")\n",
    "    try:\n",
    "        # Construcci√≥n de solicitud seg√∫n documentaci√≥n\n",
    "        datapoint = aiplatform_v1.IndexDatapoint(\n",
    "            datapoint_id=\"query_embedding\",\n",
    "            feature_vector=vector_de_la_pregunta\n",
    "        )\n",
    "\n",
    "        query = aiplatform_v1.FindNeighborsRequest.Query(\n",
    "            datapoint=datapoint,\n",
    "            neighbor_count=cantidad_de_resultados\n",
    "        )\n",
    "\n",
    "        request = aiplatform_v1.FindNeighborsRequest(\n",
    "            index_endpoint=INDEX_ENDPOINT,\n",
    "            deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "            queries=[query],\n",
    "            return_full_datapoint=True\n",
    "        )\n",
    "\n",
    "        # Ejecutar la solicitud\n",
    "        response = client.find_neighbors(request)\n",
    "\n",
    "        # Procesamiento de resultados (se mantiene igual)\n",
    "        uris_completas = []\n",
    "        if response and response.nearest_neighbors:\n",
    "            for neighbor in response.nearest_neighbors[0].neighbors:\n",
    "                segment_id_base = neighbor.datapoint.datapoint_id\n",
    "                match = re.match(r\"(.*_)(\\d+)\", segment_id_base)\n",
    "                if match:\n",
    "                    prefijo, numero = match.groups()\n",
    "                    # C√°lculo del segmento real (dividiendo entre 4)\n",
    "                    segmento_real = int(numero) // 4\n",
    "                    # Formateo a 3 d√≠gitos\n",
    "                    numero_formateado = f\"{segmento_real:03d}\"\n",
    "                    nombre_archivo_final = f\"{prefijo}{numero_formateado}\"\n",
    "                    uri = f\"/{nombre_archivo_final}\"\n",
    "                    uris_completas.append(uri)\n",
    "\n",
    "        print(f\"PASO 2.4: ¬°√âxito! embeddings encontradas: {uris_completas}\")\n",
    "        return uris_completas\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurri√≥ un error al consultar Vertex AI Search: {e}\")\n",
    "        return []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "e6f2beeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INICIANDO PROCESO DE RAG MULTIMODAL ---\n",
      "PASO 2.1: Creando embedding para la pregunta: 'Caliente.mx, caliente en pantalla, anuncio de caliente, caliente palabra'\n",
      "PASO 2.2: Configurando cliente de Vector Search...\n",
      "PASO 2.3: Buscando 5 videos similares...\n",
      "Ocurri√≥ un error al consultar Vertex AI Search: 503 failed to connect to all addresses; last error: UNAVAILABLE: ipv4:34.36.170.103:443: Failed to connect to remote host: Timeout occurred: FD shutdown\n",
      "\n",
      "--- RESPUESTA FINAL DE GEMINI ---\n",
      "No se encontraron videos relevantes para analizar.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# --- 4. EJECUCI√ìN DEL FLUJO COMPLETO (Sin cambios) ---\n",
    "# --------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    pregunta_del_usuario = \"Caliente.mx, caliente en pantalla, anuncio de caliente, caliente palabra\"\n",
    "    print(\"--- INICIANDO PROCESO DE RAG MULTIMODAL ---\")\n",
    "    uris_relevantes = buscar_videos_similares4(pregunta_del_usuario)\n",
    "    respuesta_final = analizar_fragmentos_con_gemini(pregunta_del_usuario, uris_relevantes)\n",
    "    print(\"\\n--- RESPUESTA FINAL DE GEMINI ---\")\n",
    "    print(respuesta_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
