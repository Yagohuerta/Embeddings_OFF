{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08490beb",
   "metadata": {},
   "source": [
    "# En este notebook vamos a ilustrar el proceso de creación de un RAG multimodal, para la mejora de precisión en el proyecto de Wivboost de embeddings de los videos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fba5e83",
   "metadata": {},
   "source": [
    "# **Importamos las dependencias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78eed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install rich -q\n",
    "\n",
    "# Fijate en las versiones de las librerías que se instalan, son para que no haya problemas de compatibilidad\n",
    "# %pip install --upgrade google-cloud-aiplatform==1.71.1 vertexai==1.71.1 pymupdf rich colorama -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3d32e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Importaciones para Manejo de Archivos y Directorios ---\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# --- Importamos Vertex AI ---\n",
    "import vertexai\n",
    "\n",
    "\n",
    "# --- Importaciones para Visualización y Formato de Texto ---\n",
    "\n",
    "# Se utiliza para mostrar contenido enriquecido, como texto con formato Markdown,\n",
    "# directamente en entornos como Jupyter Notebooks o IPython.\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Importa la clase `Markdown` de la biblioteca `rich`, que sirve para renderizar\n",
    "# Markdown con formato avanzado en la terminal. Se le da un alias `RichMarkdown`\n",
    "# para evitar conflictos de nombre con la importación anterior.\n",
    "from rich.markdown import Markdown as RichMarkdown\n",
    "\n",
    "\n",
    "# --- Importaciones para el Modelo Generativo de Vertex AI ---\n",
    "\n",
    "# Importa las clases necesarias del SDK de Vertex AI para interactuar con los modelos generativos.\n",
    "# - GenerationConfig: Para configurar los parámetros de la respuesta (ej. temperatura, top_p).\n",
    "# - GenerativeModel: La clase principal para cargar y usar un modelo generativo como Gemini.\n",
    "# - Image: Para manejar y enviar imágenes como parte de la entrada al modelo (enfoque multimodal).\n",
    "from vertexai.generative_models import GenerationConfig, GenerativeModel, Image\n",
    "\n",
    "# --- Inicialización del Modelo de Lenguaje (LLM) ---\n",
    "\n",
    "# Crea una instancia de un modelo generativo, cargando específicamente el modelo 'gemini-2.0-flash'.\n",
    "# Este objeto `modelo` se usará para enviar prompts (instrucciones) y recibir respuestas del LLM.\n",
    "text_model = GenerativeModel('gemini-2.0-flash')\n",
    "multimodal_model = text_model\n",
    "multimodal_model_flash = text_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91ef0cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building synchronization state...\n",
      "If you experience problems with multiprocessing on MacOS, they might be related to https://bugs.python.org/issue33725. You can disable multiprocessing by editing your .boto config or by adding the following flag to your command: `-o \"GSUtil:parallel_process_count=1\"`. Note that multithreading is still available even if you disable multiprocessing.\n",
      "\n",
      "Starting synchronization...\n",
      "If you experience problems with multiprocessing on MacOS, they might be related to https://bugs.python.org/issue33725. You can disable multiprocessing by editing your .boto config or by adding the following flag to your command: `-o \"GSUtil:parallel_process_count=1\"`. Note that multithreading is still available even if you disable multiprocessing.\n",
      "\n",
      "Copying gs://github-repo/rag/intro_multimodal_rag/intro_multimodal_rag_old_version/class_a_share.png...\n",
      "Copying gs://github-repo/rag/intro_multimodal_rag/intro_multimodal_rag_old_version/data/google-10k-sample-part2.pdf...\n",
      "Copying gs://github-repo/rag/intro_multimodal_rag/intro_multimodal_rag_old_version/data/google-10k-sample-part1.pdf...\n",
      "Copying gs://github-repo/rag/intro_multimodal_rag/intro_multimodal_rag_old_version/intro_multimodal_rag_utils.py...\n",
      "Copying gs://github-repo/rag/intro_multimodal_rag/intro_multimodal_rag_old_version/tac_table_revenue.png...\n",
      "- [5/5 files][882.3 KiB/882.3 KiB] 100% Done                                    \n",
      "Operation completed over 5 objects/882.3 KiB.                                    \n",
      "Download completed\n"
     ]
    }
   ],
   "source": [
    "# --- Descargamos otras deoendencias extra que nos marca el repo, además de el archivo ---\n",
    "!gsutil -m rsync -r gs://github-repo/rag/intro_multimodal_rag/intro_multimodal_rag_old_version .\n",
    "print(\"Download completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1526aa46",
   "metadata": {},
   "source": [
    "Usan estos datos: [Google-10k](https://abc.xyz/assets/investor/static/pdf/20220202_alphabet_10K.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b3d2bd",
   "metadata": {},
   "source": [
    "# **Configuración de las credenciales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff44a9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID: spry-byway-462510-i4\n"
     ]
    }
   ],
   "source": [
    "# --- Carga las Variables de Entorno ---\n",
    "load_dotenv()\n",
    "\n",
    "# Ejecutamos los  comandos de terminal para obtener el ID del proyecto de Google Cloud\n",
    "PROJECT_ID = subprocess.check_output(['gcloud', 'config', 'get-value', 'project'], text = True).strip()\n",
    "\n",
    "# Verificamos\n",
    "print(f'Project ID: {PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf92798d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Iniciamos vertex AI ---\n",
    "vertexai.init(project = PROJECT_ID, location = 'us-central1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666edbae",
   "metadata": {},
   "source": [
    "# **Extraemos la metadata del documento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9642f3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos una dependencia adicional para obtener la metadata\n",
    "from intro_multimodal_rag_utils import get_document_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a055e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Proceso completado ----\n"
     ]
    }
   ],
   "source": [
    "# Aquí están los pdf que vamos a utilizar para el ejemplo\n",
    "pdf_folder_path = 'Jupyter/Ejemplo_RAG/data'\n",
    "\n",
    "\n",
    "# Hacemos el prompt para las imagenes (originalmente estaba en inglés, lo traduje al español)\n",
    "image_description_prompt =\"\"\"\n",
    "Explica lo que está pasando en la imagen.\n",
    "\n",
    "Si es una tabla, extraiga todos los elementos de la tabla.\n",
    "\n",
    "Si es un gráfico, explique los hallazgos en el gráfico.\n",
    "\n",
    "No incluya ningún número que no se mencione en la imagen.\n",
    "\"\"\"\n",
    "\n",
    "# Extraemos el texto y las imágenes de los PDFs\n",
    "text_metadata_df, image_metadata_df = get_document_metadata(\n",
    "\n",
    "    multimodal_model,\n",
    "    pdf_folder_path,\n",
    "    image_save_dir = 'Jupyter/Ejemplo_RAG/images',\n",
    "    image_description_prompt = image_description_prompt,\n",
    "    embedding_size = 1408\n",
    "\n",
    ")\n",
    "\n",
    "print(\"---- Proceso completado ----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "079bfcdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd337fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class_a_share.png', 'tac_table_revenue.png']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('/Users/wivboost/Desktop/Embeddings_OFF/Jupyter/Ejemplo_RAG/images'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
